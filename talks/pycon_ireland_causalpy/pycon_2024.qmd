---
title: "Uncertainty and Causal Inference in Python"
subtitle: "CausalPy and Quasi-Experimental Designs"
author: 
    - name: Nathaniel Forde
      affiliations: 
        - Data Science @ Personio
        - and Open Source Contributor @ PyMC
format: 
    revealjs:
         theme: [default, clean.scss]
         footer: "Causal Inference in Python"
categories: [bayesian, missing data, causal inference]
image: "images/causalpy.webp"
date: last-modified
draft: False
---

# The Pitch (WIP)

Causal inference in practice needs to be credible. 

Human beings (stakeholders too) are good intuitive causal reasoners and will be suspicious of grand causal claims. Your inferential strategies need to be transparent and defensible. 

This is where you should leverage `CausalPy` and Bayesian causal modelling. 

## Agenda

- Being a Data Scientist in Industry
    - The "Good enough" rule and other varieties of Satisficing
- Causal Inference, Defensive coding and Credibility
- Bayesian Causal Models and Design Patterns
- IV designs and Instruments
- PS designs and Weighting Schemes
- Conclusion


## Data Science in Industry
### and other varieties of Satisficing


![Where do we get to if everyone does the minimum? \n
 An eye for an eye will leave everyone blind.](images/satisficing.png)

## Directionally Correct ... {.smaller}
### Maybe in a ZIRP world

:::: {.columns}

::: {.column width="60%"}
![Directionally Correct, Magnitude Poor](images/magnitude-of-a-vector.png)
:::


::: {.column width="40%"}
- Important investment decisions require a view of magnitude and direction. 
- Most business decisions reflect some kind of investment
    - But time and effort are harder to place on a balance sheet
- Only sound causal inference supports generalisable decision rules
- __"Directionally Correct" is a Zero-interest-rate-phenomena.__
:::

::::

## Experiment Recipes, Rules and Responsibility{.smaller}

:::: {.columns}

::: {.column width="30%"}
![One Rule to rule them all?](images/p-value.jpg)
![Valid](images/valid.jpg)
:::


::: {.column width="70%"}
::: {.fragment .fade-in}
- P-value based decision criteria on policy change questions are based on the null model of an asymptotic univariate distribution. 
:::
::: {.fragment .fade-in}
- Most aggregate data (e.g. Total Revenue) we see in industry result from a complex array of mixture distributions and any long-run aggregates take time to converge. 
:::
::: {.fragment .fade-in}
- Management often doesn't want to spend the time to validate the long-run characteristics of a phenomena that we would observe in a well powered A/B test.
:::
::: {.fragment .fade-in}
- Risks underpowered experiments through a __[HIPPO-like decision rules]{.red}__ and costly mistakes, ungeneralisable effects. 
:::
::: {.fragment .fade-in}
- __Challenge__: How to improve decision quality in a resource constrained/time-bound environment?
:::
:::
::::

## Causal Inference, Crediblility {.smaller}
### ... and Quasi-Experimental Design


:::: {.columns}

::: {.column width="60%"}
![](images/dataspeak.png)

:::


::: {.column width="40%"}

::: {.fragment .fade-in}
- If the data can speak for itself, the answer is ussually __[blindingly obvious]{.red}__ or has taken an inordinate amount of time to accumulate
:::

::: {.fragment .fade-in}
- __Conversely__, if we've modeled the data generating process we can answer an array of subtle questions about __[cause]{.blue}__ and __[effect]{.blue}__ that support effective decision-making.
:::
::: {.fragment .fade-in}
- Build credibility through linking theoretical estimand and empirical data while partnering across the business with subject matter experts.
:::
:::

::::

## CausalPy and Bayesian Inference {.smaller}

:::: {.columns}

::: {.column width="60%"}
![](images/causalpy.webp)
:::

::: {.column width="40%"}

- A __[python package](https://causalpy.readthedocs.io/en/latest/index.html)__ for Bayesian Models and Causal Inference methods
- Developed and maintained by @PyMC Labs 
- Broad Coverage of quasi-experimental designs.

![](images/star_hist.png)
:::

::::


## Causal Methods and Models

:::: {.columns}

::: {.column width="40%"}

![](images/causalpy_toc.png)

:::

::: {.column width="60%"}

![](images/framework.png)
Causal question(s) of import can be interrogated just when we can pair a research design with an __appropriate__ statistical model. 

:::
::::

## Canonical DAGs and Methods

:::: {.columns}

::: {.column width="50%"}

![Random Control Trial](images/rct_dag.webp)
![Instrumental Variable Design](images/iv_dag.webp)

:::

::: {.column width="50%"}

The treatment effect can be estimated cleanly
$$ y \sim 1 + Z $$


The treatment effect has to be estimated so as to avoid the bias due to X
$$ y \sim 1 + \overbrace{Z} $$
$$ \overbrace{Z} \sim 1 + IV $$ 

:::
::::


## IV Regression in CausalPy

```{{python}}
N = 100
e1 = np.random.normal(0, 3, N)
e2 = np.random.normal(0, 1, N)
Z = np.random.uniform(0, 1, N)
## Ensure the endogeneity of the the treatment variable
X = -1 + 4 * Z + e2 + 2 * e1
y = 2 + 3 * X + 3 * e1

test_data = pd.DataFrame({"y": y, "X": X, "Z": Z})

sample_kwargs = {
    "tune": 1000,
    "draws": 2000,
    "chains": 4,
    "cores": 4,
    "target_accept": 0.99,
}
instruments_formula = "X  ~ 1 + Z"
formula = "y ~  1 + X"
instruments_data = test_data[["X", "Z"]]
data = test_data[["y", "X"]]
iv = InstrumentalVariable(
    instruments_data=instruments_data,
    data=data,
    instruments_formula=instruments_formula,
    formula=formula,
    model=InstrumentalVariableRegression(sample_kwargs=sample_kwargs),
)

```


## Bayesian Structural Model {.smaller}
### And Instrument Strength

$$\begin{align*}
\left(
\begin{array}{cc}
Y \\
Z
\end{array}
\right)
& \sim
\text{MultiNormal}(\color{green} \mu, \color{purple} \Sigma) \\
\color{green} \mu & = \left(
\begin{array}{cc}
\mu_{y} \\
\mu_{z}
\end{array}
\right)
=
\left(
\begin{array}{cc}
\beta_{00} + \color{blue} \beta_{01}Z ... \\
\beta_{10} + \beta_{11}IV ...
\end{array}
\right)
\end{align*} 
$$

The treatment effect $\color{blue}\beta_{01}$ of is the primary quantity of interest

::: {.fragment .fade-in}
$$ \color{purple} \Sigma  = \begin{bmatrix}
1 & \color{blue} \sigma \\
\color{blue} \sigma & 1
\end{bmatrix} 
$$

The Bayesian estimation strategy incorporates two structural equations and the success of the IV model relies of the correlation between terms. 
:::

## Returns to Schooling: Concrete Example

:::: {.columns}

::: {.column width="50%"}
![](images/ability_edu.png)

:::


::: {.column width="50%"}

__Recipe of Assumptions__:

- Exclusion Restriction
- Independence
- Relevance
:::

::::


## Returns to Schooling: Instrument Relevance

:::: {.columns}

::: {.column width="60%"}
![Visual check of relevance for different instrument variables on the outcome](images/nearness.webp)
:::


::: {.column width="40%"}
We want to argue for: 

- the relevance of our instrument i.e. that it has a non-trivial impact on the outcome of interest

- that it influences the result only via the treatment condition. 

- evaluating multiple instrument candidates


:::

:::: 

## Returns to Schooling: Quantifying Confounding {.smaller}

:::: {.columns}

::: {.column width="40%"}
![Comparison between IV and OLS model parameter estimates](images/compare_ols.webp)
:::


::: {.column width="0%"}
The natural comparison with OLS shows:

- evidence of genuine confounding in the estimates of treatment effect

- Crucially it highlights the false precision in the OLS estimate.

:::
:::: 


## Returns to Schooling: Justifying Instruments {.smaller}

:::: {.columns}

::: {.column width="40%"}
![Samples from LKJ prior on Covariance structure with different prior settings](images/priors_on_corr.webp)
:::


::: {.column width="60%"}
The strength of an instrument is determined by the correlation structure between instrument and outcome via the treatment solely:

- F-tests can be used to assess how the instrument relates to the outcome.

- In the Bayesian setting we can directly estimate the correlation structure and apply sensitivity tests.

:::
:::: 


## Returns to Schooling: Sensitivity Analysis and Model Evaluation 

:::: {.columns}

::: {.column width="40%"}
![Parameter estimates across different model formulations](images/model_comparison.webp)
:::


::: {.column width="60%"}
![Posterior Predictive checks and Marginal Effects on our best IV model](images/final_iv_model.webp)


:::
:::: 

