---
title: "Bayesian Structural Causal Inference"
subtitle: "Exploring Space, Finding Structure, Testing Robustness"
author: "Nathaniel Forde"
institute: |
  Data Science @ Personio  
  Open Source Contributor @ PyMC
image: "images/probabilistic_intervention_fix.webp"
format: 
  revealjs:
    theme: [default, clean.scss]
    transition: fade
    slide-number: true
    preview-links: auto
    width: 1200
    height: 750
---

## Preliminaries {.smaller}

:::{.callout-warning}
## Who am I?
- I'm a __data scientist__ at __[Personio]{.blue}__ 
    - Bayesian statistician, 
    - Reformed philosopher and logician. 
- Website: [https://nathanielf.github.io/](https://nathanielf.github.io/)
:::
 
::: {.callout-tip}
## Code or it didn't Happen
The worked examples used here can be found [here](https://www.pymc-marketing.io/en/latest/notebooks/customer_choice/nested_logit.html)
:::

![My Website](images/QR_CODE.png)


## The Pitch: World-Building Matters

Scientific success hinges on understanding that __outcomes are driven by hidden structures, unobserved correlations, and selection mechanisms.__ 

Structural causal modelling allows you to simulate system interventions safely, mapping the multiverse of potential outcomes to find the one world where your strategy actually works, and quantify where it might.

## Agenda
  - The Metaphor: The Physics of the Fish Tank
  - The Invisible Threat: Hidden Confounding and $\rho$
  - The Pruning: Variable Selection as World Elimination
  - The Pitfalls: Why Total Flexibility Destroys Identification
  - The Navigation: Mapping the Multiverse of Results

# The Metaphor

![](images/probabilistic_intervention_fix.webp)


## The Pet Shop Problem

:::: {.columns}
::: {.column width="60%"}
A causal analyst is like a pet-shop owner introducing a new fish to an aquarium.

**The Question:** "Does this fish survive?"

**Wrong Focus:** The fish's intrinsic properties (the "Treatment" in isolation).

**Right Focus:** The physics of the tank—pH, predators, currents (the "Structural" environment).
:::

::: {.column width="40%"}
::: {.callout-important}
## The Insight
"What is the causal effect?" really asks:

**"In which world are we operating?"**
:::
:::
::::


## Two Philosophies of the Tank

:::: {.columns}
::: {.column width="50%"}
### Design-Based Minimalism
**Philosophy:** Find a "clean" corner of the tank (Natural Experiments).

**Strength:** Robust to local errors.  
**Limitation:** If the whole tank is cloudy, you're blind.
:::

::: {.column width="50%"}
### Structural Maximalism
**Philosophy:** Model the pumps, filters, and chemistry explicitly.

**Strength:** Explains *why* the fish survives.  
**Limitation:** If the physics model is wrong, the prediction fails.
:::
::::

. . .

> **The Bayesian Commitment:** We don't know the exact physics. We use data to eliminate impossible tank setups and explore the plausible ones.

## Joint Structural Modelling

![](images/complex_structure.svg)

# The Mechanics of "The Tank"

## The Two Movements of Inference
:::: {.columns}
::: {.column width="50%"}
Causal inference in a structural framework is a two-step dance:

1.  **Backwards (Inference):** Use observed Treatment ($T$) and Outcome ($Y$) to infer the hidden state of the world ($w$).
2.  **Forwards (Counterfactual):** Use that world state to simulate what *would* happen if we changed $T$.
:::

::: {.column width="50%"}
![](images/forwards_backwards.webp)
:::
:::

## The Invisible Threat: Hidden Correlation

The confounding isn't just in what we *measure*—it's in the covariance of the errors:

$$
\begin{pmatrix} U \\ V \end{pmatrix} \sim N\left(0, \begin{bmatrix} \sigma_U^2 & \rho\sigma_U\sigma_V \\ \rho\sigma_U\sigma_V & \sigma_V^2 \end{bmatrix}\right)
$$

. . .

* **$\rho = 0$:** The OLS assumption. $T$ is "as-if" random.
* **$\rho \neq 0$:** The Structural reality. Selection bias is modeled as a parameter.

## The Bias is Real: OLS Drift

![OLS estimates drift as ρ varies](images/ols_bias.webp){fig-align="center" width="70%"}

If we ignore $\rho$, our estimate of the effect ($\alpha$) is a ghost. It's not just "noisy"—it's fundamentally misplaced because we've ignored the unobserved "currents" in the tank.

# Finding Structure (Pruning)

## Discovering Structure as World Elimination

How do we find the "right" tank physics? We use **Variable Selection Priors** to collapse the multiverse.

:::: {.columns}
::: {.column width="50%"}
### Spike-and-Slab
**The Sieve:** It forces coefficients to be exactly zero or significantly non-zero. 

**Result:** Eliminates worlds where irrelevant variables act as noise.
:::

::: {.column width="50%"}
### Horseshoe
**The Funnel:** It provides global and local shrinkage.

**Result:** Progressively prunes weak "paths" in the causal graph until only the strongest structural links remain.
:::
::::

## Variable Selection Priors and Instrument Discovery
:::: {.columns}
::: {.column width="60%"}
![](images/variable_selection.webp)
:::

::: {.column width="40%"}
![](images/JOINT_DAG.webp)
:::
::::


## Wrong turns in the Multiverse

::: {.callout-caution}
## The BART Pitfall
Using "Infinite Flexibility" (BART/GPs) in the **Outcome** equation is dangerous.
:::

**Why?** If the model can explain $Y$ through any arbitrary "wiggle," it will "soak up" the causal signal. 

* **Outcome Flexibility:** The model hides the effect of $T$ inside the flexibility of the curve. $\alpha$ becomes unidentifiable.
* **Treatment Flexibility:** Safe. It helps us model the "selection" process more accurately without obscuring the causal link.


## Identification Denied

![](images/bart_comparison.webp)

BART outcome model absorbs the structural distinction between treatment and other covariates, rendering the treatment effect surplus to purpose. The signal is swallowed by the noise-handler.

# Navigating the Multiverse (Exploration)

## Mapping the Multiverse

We don't estimate a point; we map a territory.

:::: {.columns}
::: {.column width="70%"}
![](images/sensitivity_rho.webp)
:::

::: {.column width="30%"}
```python
# We explore different 'Universes' of confounding
priors = {
  "Exogenous": pm.DiracDelta(0),
  "Moderate": pm.Normal(0, 0.2),
  "Deep Selection": pm.TruncatedNormal(0.5, 0.1, lower=0)
  ...
```
:::
::::


## Causal Inference and Counterfactual Worlds

![](images/potential_outcomes.webp)

## Case Study: Smoking and Weight

| World | $\hat{\alpha}$ (Effect) | Interpretation |
|-------|-----------|----------------|
| **OLS (Naive)** | 3.3 | Ignores the physics of selection. |
| **Bayesian ($\rho=0$)** | 5.1 | Models structural links, assumes no hidden bias. |
| **Bayesian ($\rho \approx -0.3$)** | 6.2 | Accounts for the "unobserved" drivers of quitting. |

. . .

::: {.callout-important}
## The "Bias Gap"
The difference between 3.3 and 6.2 is the "Cost of Ignorance." The OLS benchmark assumes conditional ignorability. The various joint models allow for latent confounding i.e. that the covariate profile used in the study is not sufficiently exhaustive to block all confounding. 
:::

## Testing Robustness 

![](images/nhefs.webp)

We assess the range of treatment effects under a variety of model specifications including a BART treatment equation. 


# Conclusion

## The Bayesian Causal Workflow

1.  **Backwards Movement:** Use the joint model to infer the likely world state ($w, \rho$).
2.  **Elimination:** Use Spike-and-Slab/Horsehoe to prune implausible causal architectures.
3.  **Exploration:** Map treatment effects across the "Multiverse" of plausible $\rho$ values.

. . .

1.  **"Which worlds did you eliminate?"** (Variable selection/DAG pruning)
2.  **"Which worlds did you explore?"** (Sensitivity analysis across $\rho$)
3.  **"Where did you put the flexibility?"** (Did you ensure identifiability?)


