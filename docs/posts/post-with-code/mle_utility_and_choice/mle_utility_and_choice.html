<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nathaniel Forde">
<meta name="dcterms.date" content="2021-02-21">

<title>Examined Algorithms - Trains, Planes …Utility and Maximum Likelihood</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Examined Algorithms</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../opensource.html">
 <span class="menu-text">Open Source Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../talks.html">
 <span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../resume/Nathaniel_Forde_CV.pdf">
 <span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-reader-toggle nav-link" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Trains, Planes …Utility and Maximum Likelihood</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block">Trains, Planes …Utility and Maximum Likelihood</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">mle</div>
                <div class="quarto-category">revealed preference</div>
                <div class="quarto-category">log-likelihood</div>
                <div class="quarto-category">utility</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Nathaniel Forde </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 21, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">Logic</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notes/certain_things/Public/Logic/Introduction - Logic Topics.html" class="sidebar-item-text sidebar-link">Introduction - Logic Topics</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">Philosophy</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notes/certain_things/Public/Philosophy/Introduction - Philosophy Topics.html" class="sidebar-item-text sidebar-link">Introduction - Philosophy Topics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notes/certain_things/Public/Philosophy/Thinking about Statistics.html" class="sidebar-item-text sidebar-link">Statistical Models and the Problem of Induction</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notes/certain_things/Public/Philosophy/Sorites Paradox and Survival Analysis.html" class="sidebar-item-text sidebar-link">The Sorites Paradox</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">Statistics</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notes/certain_things/Public/Statistics/Introduction - Statistics Topics.html" class="sidebar-item-text sidebar-link">Introduction - Statistics Topics</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../notes/certain_things/Public/Statistics/Analogies between Missing Data and Causal Inference.html" class="sidebar-item-text sidebar-link">Taxonomies of Missing-ness</a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#revealed-preference-a-political-need" id="toc-revealed-preference-a-political-need" class="nav-link active" data-scroll-target="#revealed-preference-a-political-need">Revealed Preference: a Political Need</a>
  <ul class="collapse">
  <li><a href="#latent-utility-and-binary-preference" id="toc-latent-utility-and-binary-preference" class="nav-link" data-scroll-target="#latent-utility-and-binary-preference">Latent Utility and Binary Preference</a></li>
  <li><a href="#probit-and-logit-regressions-for-binary-choice" id="toc-probit-and-logit-regressions-for-binary-choice" class="nav-link" data-scroll-target="#probit-and-logit-regressions-for-binary-choice">Probit and Logit Regressions for Binary Choice</a></li>
  <li><a href="#maximum-likelihood-estimation-and-multiple-choice" id="toc-maximum-likelihood-estimation-and-multiple-choice" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-and-multiple-choice">Maximum Likelihood Estimation and Multiple Choice</a></li>
  <li><a href="#bart-and-transportation-policy." id="toc-bart-and-transportation-policy." class="nav-link" data-scroll-target="#bart-and-transportation-policy.">BART and Transportation policy.</a></li>
  </ul></li>
  <li><a href="#the-tension-idealisation-reality-and-progress" id="toc-the-tension-idealisation-reality-and-progress" class="nav-link" data-scroll-target="#the-tension-idealisation-reality-and-progress">The Tension: Idealisation, Reality and Progress</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>In <em>The Century of Self</em> Adam Curtis’ spiralling survey of the 20th century we’re shown how the Freud’s ideas seeped into public consciousness. How they were taken and deployed by ad-men and marketing gurus to sell our own initimated desires back to ourselves. There is a conceit of individuality and uniqueness - that our mind is our own and the choices we make are ours alone to know and learn from. We plot our own journies and cleave to their contours as if we can see the goal. The main players and places get reshuffled or recycled as we grow, the tale contorts and twists to our constant surprise. How then could we be so utterly predictable?</p>
<section id="revealed-preference-a-political-need" class="level1">
<h1>Revealed Preference: a Political Need</h1>
<p>The hope of many marketers is that your individuality is irrelevant to your consumption. As long as you fall into an identifiable class of consumer, your habits can be exploited and directed. Your propensity to purchase might be inferred from the past behaviour of similar consumers. This slightly nefarious motivation obscures the audacity of the project. The notion that we can model and predict your behaviour based on estimating some unobserved or latent motivation is radical. It postulates a subjective measure of utility and aims to approximate those dimensions of your preferences. This is a theory that human motivations can be modeled and the question is how, not why.</p>
<p>In this blog post we’ll dig into some of the details of Daniel McFadden’s analyis of the BART transport system in San Francisco and the algorithmic approach he took to estimating the preferences of the San Francisco residents. He used this analysis to accurately predict the uptake in the rail-users within the city thereby showing that a sound understanding of the incentives and pressures on city infrastructure can lead to accurate predictions of citizenry.</p>
<p>But put aside the fears of conspiratorial manipulation, the task is hard and the measures of success are few and far between. More to the point, it is probably to our benefit as a society that some stability can be discerned from patterns of our behaviour. Policy research and politics more generally is based on the assumption that we ought to try and cater to the preferences of citizens. The question of how to discern those preferences is more urgent than how to market products. Representative democracies claim voting is revelatory while marketers maintain that consumption is a leading indicator but both are in the business of articulating need.</p>
<section id="latent-utility-and-binary-preference" class="level2">
<h2 class="anchored" data-anchor-id="latent-utility-and-binary-preference">Latent Utility and Binary Preference</h2>
<p>We’ll start, following the presentation of Christopher Adam’s <em>Learning Microeconometrics</em>, with a simple case of binary choice between goods <span class="math inline">\(A, B\)</span>.</p>
<p><strong>Revealed Preference Axiom</strong>: If there are two choices, A and B, and we observe a person choose A, then her utility from A is greater than her utility from B.</p>
<p>We assume that the latent utility can be expressed as by the revealed preferences i.e.&nbsp;as the share or proportion of choices made by the customers. Some assumptions about the form of the utility distribution are crucial as our modeling efforts will go wrong if we know nothing about the latent utilities. The utility is some function of product and consumer’s properties, perhaps mostly driven by price</p>
<p><span class="math display">\[ utility = \mathbf{X'}\beta + v\]</span></p>
<p>and market share is an expression of that utility</p>
<p><span class="math display">\[ demand_A = utility_{A} &gt; 0 \]</span></p>
<p>In a choice context we’re trying to determine if the implicit utility measure is sufficient to drive a purchase, and as such OLS models are inappropriate. This stems from the fact that we’re’trying to estimate a conditional probability over a binary choice not a unbounded continuous measure. The revealed preference assumption says that we can predict the purchase if the utility of the good is positive.</p>
<p><span class="math display">\[Pr(demand_A = 1) = utility &gt; 0 \]</span> <span class="math display">\[= Pr(\mathbf{X'}\beta + v &gt; 0) \]</span> <span class="math display">\[ = Pr(v &gt; - \mathbf{X'}\beta ) \]</span> <span class="math display">\[ = 1 - F(\mathbf{X'}\beta ) \]</span></p>
<p>where <span class="math inline">\(F\)</span> is the distribution of the unobserved random variable <span class="math inline">\(v\)</span>. The challenge is using the correct distribution as this feeds the method of statistical estimation of the parameters <span class="math inline">\(\beta\)</span></p>
<p><span class="math display">\[U\_{i,A} &gt; U_{i, B} \]</span></p>
<p>just when</p>
<p><span class="math display">\[ \mathbf{X'}_{i, A}\beta + v_{i,A} &gt; \mathbf{X'}_{i, B}\beta + v_{i,B}\]</span></p>
<p>or</p>
<p><span class="math display">\[  v\_{i,A} -  v\_{i,B} &gt; - (\mathbf{X'}_{i, A}  - \mathbf{X'}_{i, B})\beta \]</span></p>
<p>but then the probability of demand is just</p>
<p><span class="math display">\[Pr(demand_A = 1 | \mathbf{X'}_{i, A}, \mathbf{X'}_{i, B}) \]</span> <span class="math display">\[ = Pr\Bigg( v_{i,A} -  v_{i,B} &gt; - (\mathbf{X'}_{i, A}  - \mathbf{X'}_{i, B})\beta \Bigg) \]</span> <span class="math display">\[ = Pr\Bigg( -v_{i,A} -  v_{i,B} &lt; (\mathbf{X'}_{i, A}  - \mathbf{X'}_{i, B})\beta \Bigg) \]</span> <span class="math display">\[ = F\Bigg( (\mathbf{X'}_{i, A}  - \mathbf{X'}_{i, B})\beta \Bigg) \]</span></p>
<p>There are a number of candidate distributions that might serve our purposes we’ll look here at the logistic regression and probit binary classification modes.</p>
</section>
<section id="probit-and-logit-regressions-for-binary-choice" class="level2">
<h2 class="anchored" data-anchor-id="probit-and-logit-regressions-for-binary-choice">Probit and Logit Regressions for Binary Choice</h2>
<p>The probit and logit models are convenient distributions for modeling discrete choice. We’ll initialise some fake data and build two models over the <span class="math inline">\(X, y\)</span> to infer the parameterisations that determined the utility driving of our choices. Note that we specify the distributions of the rror term differently for both models. In the probit case we say that the error term is normally distributed and in the logit case our error term is given a Weibull distribution.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>X_A <span class="op">=</span> sm.add_constant(np.random.rand(N,<span class="dv">2</span>))</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>X_B <span class="op">=</span> sm.add_constant(np.random.rand(N, <span class="dv">2</span>))</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#probit we only need one normal error term since sums of normals are normal</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>v <span class="op">=</span> np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, N)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (X_A.dot(beta) <span class="op">-</span> X_B.dot(beta)) <span class="op">+</span> v <span class="op">&gt;</span> <span class="dv">0</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>X_diff <span class="op">=</span> X_A <span class="op">-</span> X_B</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>X_diff[:, <span class="dv">0</span>] <span class="op">=</span>  <span class="dv">1</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X_diff <span class="op">=</span> pd.DataFrame(X_diff, columns<span class="op">=</span>[<span class="st">'const'</span>, </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="st">'product_desc'</span>, <span class="st">'product_desc1'</span>])</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Probit model</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>probit_mod <span class="op">=</span> sm.Probit(y, X_diff)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>probit_res <span class="op">=</span> probit_mod.fit()</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>v1 <span class="op">=</span> np.random.weibull(<span class="dv">1</span>, N)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>v2 <span class="op">=</span> np.random.weibull(<span class="dv">1</span>, N)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (X_A.dot(beta) <span class="op">-</span> X_B.dot(beta)) <span class="op">+</span> (v1 <span class="op">-</span> v2) <span class="op">&gt;</span> <span class="dv">0</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logit model</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>logit_mod <span class="op">=</span> sm.Logit(y, X_diff)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>logit_res <span class="op">=</span> logit_mod.fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The results are pretty good for both models - slightly better for the probit model in this case as the tails of the logit are wider. Both models discern the directionality and the correct magnitude of the parameters.</p>

<table width="50%,">
<caption>
Binary Choice Probit and Logit Models
</caption>
<tbody>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td colspan="2">
<em>Dependent variable:y</em>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
</tr>
<tr>
<td>
</td>
<td colspan="1">
Probit Model
</td>
<td colspan="1">
Logit Model
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(1)
</td>
<td>
(2)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align:left">
const
</td>
<td>
-0.255<sup></sup>
</td>
<td>
-0.049<sup></sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.156)
</td>
<td>
(0.246)
</td>
</tr>
<tr>
<td style="text-align:left">
product_desc
</td>
<td>
-1.491<sup>***</sup>
</td>
<td>
-2.157<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.445)
</td>
<td>
(0.690)
</td>
</tr>
<tr>
<td style="text-align:left">
product_desc1
</td>
<td>
2.964<sup>***</sup>
</td>
<td>
3.833<sup>***</sup>
</td>
</tr>
<tr>
<td style="text-align:left">
</td>
<td>
(0.578)
</td>
<td>
(0.888)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align: left">
Observations
</td>
<td>
100
</td>
<td>
100
</td>
</tr>
<tr>
<td style="text-align: left">
R<sup>2</sup>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align: left">
Adjusted R<sup>2</sup>
</td>
<td>
</td>
<td>
</td>
</tr>
<tr>
<td style="text-align: left">
Residual Std. Error
</td>
<td>
1.000 (df=97)
</td>
<td>
1.000 (df=97)
</td>
</tr>
<tr>
<td style="text-align: left">
F Statistic
</td>
<td>
<sup></sup> (df=2; 97)
</td>
<td>
<sup></sup> (df=2; 97)
</td>
</tr>
<tr>
<td colspan="3" style="border-bottom: 1px solid black">
</td>
</tr>
<tr>
<td style="text-align: left">
Note:
</td>
<td colspan="2" style="text-align: right">
<sup><em></em></sup><em>p&lt;0.1; <sup><strong></strong></sup><strong>p&lt;0.05; <sup></sup></strong></em>p&lt;0.01
</td>
</tr>
</tbody>

</table>
</section>
<section id="maximum-likelihood-estimation-and-multiple-choice" class="level2">
<h2 class="anchored" data-anchor-id="maximum-likelihood-estimation-and-multiple-choice">Maximum Likelihood Estimation and Multiple Choice</h2>
<p>Under the hood these models are fit using the technique of maximum likelihood estimation, which searches the parameter space over each distribution to find a setting so that the observed data is most probable. For computational convenience this often means that we minimise the value of negative log likelihood over a variety of parameter settings.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_probit_dist(params, <span class="op">*</span>args):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>   X, y <span class="op">=</span> args[<span class="dv">0</span>], args[<span class="dv">1</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>   beta <span class="op">=</span> [params[<span class="dv">0</span>], params[<span class="dv">1</span>], params[<span class="dv">2</span>]]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>   mu, sd, <span class="op">=</span> params[<span class="dv">3</span>], params[<span class="dv">4</span>]</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>   Xb <span class="op">=</span> X.dot(beta)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>   q <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>y<span class="op">-</span><span class="dv">1</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>   log_lik <span class="op">=</span> np.log(stats.norm.cdf(q<span class="op">*</span>Xb))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>   <span class="cf">return</span> <span class="op">-</span><span class="bu">sum</span>(log_lik)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">### Optimise the probit model for determining the parameters required to</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">### estimate the underlying utility</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">### True values of the parameters 2, 3, -4</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(log_probit_dist, x0 <span class="op">=</span>[<span class="dv">0</span>, <span class="dv">0</span> ,<span class="dv">0</span> , <span class="dv">0</span>, <span class="dv">1</span>], </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>args <span class="op">=</span>(X, demand_A), options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>But the situation is slightly more complex when we’re trying to optimise over multiple possible choices. Even with three choices, we have to both measure each latent utility metric as a structural equation and compare the demand for each product <span class="math inline">\(T, B, C\)</span> against a specific reference product. In this case we’ll choose <span class="math inline">\(C\)</span> if the utility exceeds that of <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span>.</p>
<p><span class="math display">\[ U_{i,T} = \mathbf{X'}\beta + v_{i,T} \]</span> <span class="math display">\[ U_{i,B} = \mathbf{X'}\beta + v_{i,B} \]</span> <span class="math display">\[ U_{i,C} = \mathbf{X'}\beta + v_{i,C} \]</span> <span class="math display">\[ Pr(y_C = 1 | \mathbf{X}_{i, C}, \mathbf{X}_{i, T}) =
      Pr\Big((v_{i, C} - v_{i, B} &gt; - \mathbf{X'}_{i, C}\beta )  \\
      \text{ and } v_{i, C} - v_{i, T}  &gt; - (\mathbf{X}_{i, C}\beta - \mathbf{X}_{i, T})^{'}\beta \Big) \]</span></p>
<p>For some appropriate probability distribution. This is a strong restriction called <strong>The Irrelevance of Independent Alternatives</strong>, it bakes in the notion that our preferences are consistent and transitive. If we prefer <span class="math inline">\(C\)</span> to <span class="math inline">\(B\)</span> and <span class="math inline">\(B\)</span> to <span class="math inline">\(T\)</span> then we ought to prefer <span class="math inline">\(C\)</span> to <span class="math inline">\(T\)</span> too. The benefit of the assumption is that it allows us to infer a utility ranking metric by computing all the pairwise alternatives to a given product. The mulinomial logit distribution is a convenient measure for discrete choice problems because it allows us to express our preference for each product on a 0-1 scale given by:</p>
<p><span class="math display">\[ Pr(y_C = 1 | \mathbf{X}_{i, C}, ... \mathbf{X}_{i, j}) = \dfrac{ exp(\mathbf{X'}\beta)_{i, C}}{1 + \sum_{i, j}^{j=N} exp(\mathbf{X'}\beta)_{i, j} } \]</span></p>
<p>which can be optimised for the best parameter fits through an maximum likelihood procedure as follows:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">100</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">0</span>]</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>rho <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>cov <span class="op">=</span> [[<span class="dv">1</span>, rho], [rho, <span class="dv">1</span>]]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># u is N*2</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.random.multivariate_normal(mu, cov, <span class="dv">1000</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span>(N,<span class="dv">2</span>)) <span class="co">#np.random.rand(N,2)</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, <span class="dv">1</span>, size<span class="op">=</span>(N,<span class="dv">2</span>)) <span class="co">#np.random.rand(N,2)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> <span class="op">-</span><span class="dv">1</span> <span class="op">+</span> <span class="op">-</span><span class="dv">3</span><span class="op">*</span>x1 <span class="op">+</span> <span class="dv">4</span><span class="op">*</span>x2 <span class="op">+</span> u</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.zeros(shape<span class="op">=</span>(N, <span class="dv">2</span>))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>y[:,<span class="dv">0</span>] <span class="op">=</span> ((U[:,<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">&amp;</span> (U[:,<span class="dv">0</span>] <span class="op">&gt;</span> U[:,<span class="dv">1</span>]))</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>y[:,<span class="dv">1</span>] <span class="op">=</span> (U[:,<span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">0</span> <span class="op">&amp;</span> (U[:,<span class="dv">1</span>] <span class="op">&gt;</span> U[:,<span class="dv">0</span>]))</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>W1 <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>:x1[:,<span class="dv">0</span>], <span class="st">'x2'</span>:x2[:,<span class="dv">0</span>]})</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>W2 <span class="op">=</span> pd.DataFrame({<span class="st">'x1'</span>:x1[:,<span class="dv">1</span>], <span class="st">'x2'</span>:x2[:,<span class="dv">1</span>]})</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>y_full <span class="op">=</span> np.ones(shape<span class="op">=</span>(N<span class="op">*</span><span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>class_1 <span class="op">=</span> np.where(((U[:,<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">&amp;</span> (U[:,<span class="dv">0</span>] <span class="op">&gt;</span> U[:,<span class="dv">1</span>])), <span class="st">'class_1'</span>, <span class="st">'class_0'</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>class_2 <span class="op">=</span> np.where((U[:,<span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">0</span> <span class="op">&amp;</span> (U[:,<span class="dv">1</span>] <span class="op">&gt;</span> U[:,<span class="dv">0</span>])), <span class="st">'class_2'</span>, <span class="st">'class_0'</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>y_full <span class="op">=</span> np.append(class_1, class_2)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>W_full <span class="op">=</span> sm.add_constant(W1.append(W2)).reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cdf(W, beta):</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    Wb <span class="op">=</span> np.dot(W, beta)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    eXB <span class="op">=</span> np.exp(Wb)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    eXB <span class="op">=</span> eXB <span class="op">/</span>eXB.<span class="bu">sum</span>(<span class="dv">1</span>)[:, <span class="va">None</span>]</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> eXB</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> take_log(probs):</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-20</span> </span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.log(probs <span class="op">+</span> epsilon)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calc_ll(logged, d):</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    ll <span class="op">=</span> d <span class="op">*</span> logged</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ll</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ll_mn_logistic(params, <span class="op">*</span>args):</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    y, W, n_params, n_classes <span class="op">=</span> args[<span class="dv">0</span>], args[<span class="dv">1</span>], args[<span class="dv">2</span>], args[<span class="dv">3</span>]</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> [params[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(params))]</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> np.array(beta).reshape(n_params, <span class="op">-</span><span class="dv">1</span>, order<span class="op">=</span><span class="st">'F'</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensures fit against a reference class</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    beta[:,<span class="dv">0</span>] <span class="op">=</span> [<span class="dv">0</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, n_params)]</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">## onehot_encode</span></span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> pd.get_dummies(y, prefix<span class="op">=</span><span class="st">'Flag'</span>).to_numpy()</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>    probs <span class="op">=</span> cdf(W, beta)</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>    logged <span class="op">=</span> take_log(probs)</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>    ll <span class="op">=</span> calc_ll(logged, d)</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>np.<span class="bu">sum</span>(ll)</span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>n_params <span class="op">=</span> <span class="dv">3</span> </span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>n_classes <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> np.random.rand(<span class="dv">3</span>,<span class="dv">3</span>).flatten()</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> minimize(ll_mn_logistic, x0 <span class="op">=</span>z, args <span class="op">=</span>(y_full, W_full, n_params, n_classes), </span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>             options<span class="op">=</span>{<span class="st">'disp'</span>: <span class="va">True</span>, <span class="st">'maxiter'</span>:<span class="dv">1000</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The expressive power of these kinds of discrete choice model are to be admired. They map onto an innumerable range of practical problems in business, science and politics. So it is all the more important to be aware of their limitations when deploying them at scale. The independence assumption and the linear structure of the latent utility model is not innocent, they’re tantamount to very strong claims about the consistency and preference structure of the population. So long as we’re aware of this, the algorithms can be deployed profitably as sometimes consumers do have rational preferences - <em>the challenge is modelling the considerations that go into their reasoning.</em> It’s utterly useless to articulate preference over goods poorly described.</p>
</section>
<section id="bart-and-transportation-policy." class="level2">
<h2 class="anchored" data-anchor-id="bart-and-transportation-policy.">BART and Transportation policy.</h2>
<p>The BART infrastructure in san Francisco was expensive to implement and such rail networks can have massive impacts on the face of a city, so it is important to evaluate the potential gains to the development. McFadden’s analysis phrased this question a choice over the available modes of transport, and sought to predict the future demand for rail based on other demographic factors. The idea is that house size, ownership, income and proximity to a rail network determine uptake.</p>

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
home
</th>
<th>
HHSIZE
</th>
<th>
income
</th>
<th>
urban1
</th>
<th>
density
</th>
<th>
CHOICE
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
1
</th>
<td>
1.0
</td>
<td>
2
</td>
<td>
8.0
</td>
<td>
False
</td>
<td>
0.3
</td>
<td>
car
</td>
</tr>
<tr>
<th>
15
</th>
<td>
1.0
</td>
<td>
2
</td>
<td>
5.0
</td>
<td>
True
</td>
<td>
30.0
</td>
<td>
rail
</td>
</tr>
<tr>
<th>
17
</th>
<td>
0.0
</td>
<td>
3
</td>
<td>
5.0
</td>
<td>
True
</td>
<td>
3.0
</td>
<td>
bus
</td>
</tr>
<tr>
<th>
18
</th>
<td>
0.0
</td>
<td>
2
</td>
<td>
7.0
</td>
<td>
True
</td>
<td>
7.0
</td>
<td>
car
</td>
</tr>
<tr>
<th>
33
</th>
<td>
1.0
</td>
<td>
3
</td>
<td>
11.0
</td>
<td>
True
</td>
<td>
1.5
</td>
<td>
car
</td>
</tr>
<tr>
<th>
…
</th>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
<td>
…
</td>
</tr>
</tbody>

</table>
<p>It’s hard to estimate demand for a new product directly, so instead he tried to develop a two step model which estimated the relative impact of the each of the demographic factors on rail use where there already existed some rail infrastructure and then project the demand as if the same conditions held throughout the city. The multinomial model fitted on parts of the city with existing infrastructure gives the following coefficient estimates for the demographic factors relative to a base choice of bus-transport.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>no_rail <span class="op">=</span> y_focus_nr[[<span class="st">'home'</span>, <span class="st">'HHSIZE'</span>, <span class="st">'income'</span>, <span class="st">'urban1'</span>, <span class="st">'density'</span>, <span class="st">'rail'</span>, <span class="st">'CHOICE'</span>]].astype(<span class="bu">float</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>rail <span class="op">=</span> y_focus_r[[<span class="st">'home'</span>, <span class="st">'HHSIZE'</span>, <span class="st">'income'</span>, <span class="st">'urban1'</span>, <span class="st">'density'</span>, <span class="st">'rail'</span>, <span class="st">'CHOICE'</span>]].astype(<span class="bu">float</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>full <span class="op">=</span> y_focus[[<span class="st">'home'</span>, <span class="st">'HHSIZE'</span>, <span class="st">'income'</span>, <span class="st">'urban1'</span>, <span class="st">'density'</span>, <span class="st">'rail'</span>, <span class="st">'CHOICE'</span>]].astype(<span class="bu">float</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>MN_logit_mod_r <span class="op">=</span> sm.MNLogit(np.array(rail[<span class="st">'CHOICE'</span>]), </span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>                       rail[[<span class="st">"home"</span>,<span class="st">"HHSIZE"</span>,<span class="st">"income"</span>,<span class="st">"urban1"</span>,<span class="st">"density"</span>]])</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>MN_logit_res_r <span class="op">=</span> MN_logit_mod_r.fit()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>MN_logit_res_r.summary()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="regression_table.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Regression Table</figcaption><p></p>
</figure>
</div>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>nr_nd <span class="op">=</span> no_rail</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>nr_nd[<span class="st">'density'</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>nr_d <span class="op">=</span> no_rail</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>nr_d[<span class="st">'density'</span>] <span class="op">=</span> r[<span class="st">'density'</span>].mean()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>full_d <span class="op">=</span> full</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>full_d[full_d[<span class="st">'rail'</span>] <span class="op">==</span> <span class="dv">0</span>][<span class="st">'density'</span>] <span class="op">=</span> r[<span class="st">'density'</span>].mean()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Predict full city uptake using model trained on rail data</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> MN_logit_res_r.predict(full.drop(<span class="st">'rail'</span>, axis<span class="op">=</span><span class="dv">1</span>)).mean()</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> pd.DataFrame(res).T</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>res.columns <span class="op">=</span> [<span class="st">'Bus'</span>, <span class="st">'Car'</span>, <span class="st">'Train'</span>]</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>res.<span class="bu">round</span>(<span class="dv">3</span>) <span class="op">*</span> <span class="dv">100</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

<table class="dataframe table table-sm table-striped">
<thead>
<tr>
<th>
</th>
<th>
Bus
</th>
<th>
Car
</th>
<th>
Train
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
2.7
</td>
<td>
88.5
</td>
<td>
8.8
</td>
</tr>
</tbody>

</table>
<p>As it turned out this estimate for rail uptake was almost perfect which raises the question: are we really predictable or was the model really lucky? There is an odd dynamic between economic models and normative behaviour - once one is formulated as an approximate theory of advantageous behaviour in a market, it seeps in the societal consciousness as we try to learn from it. In doing so we conform to a model and make it a better fit to the data. Jevon’s would observe this characteristic as early as 1871</p>
<blockquote class="blockquote">
<p>The laws [of individual economic man’s behaviour] which we are about to trace out are to be conceived as theoretically true of the individual; they can only be practically verified as regards the aggregate transactions, productions and consumptions of a large body of people. But the laws of the aggregate depend of course upon the laws applying to individual cases. - quoted on pg 149 <em>The World in the Model</em> by Mary S. Morgan</p>
</blockquote>
<p>McFadden’s work was exemplary and revolutionary. It showed a clear and principaled method for translating a theory of human motivation into a predictions of market movements. The results were perhaps a little fortunate, but the method is profoundly important. The hardwork and shoe-leather of testing numerous models against observation, trying to infer causal impact of the demographic factors all illustrated the right kind of scientific process - measurement, abstraction and forecast.</p>
<p>The discrete choice models have some particular limitations when applied to complex choices over price. Apart from the fact that consumers will often exhibit irrational preferences, price of a product is correlated with the random components of the utility measure. This can prevent proper estimation of the model without making some adjustments. We won’t dwell on the details here but it is enough to note that the urgency of the task is not diminished by the difficulty.</p>
</section>
</section>
<section id="the-tension-idealisation-reality-and-progress" class="level1">
<h1>The Tension: Idealisation, Reality and Progress</h1>
<p>The challenge of an economic model is to create a measure that abstracts over the particulars without doing violence to the participants. These models enter into a feedback loop of policy and practice. If we’re lucky our institutions learn from experimenting with these models and improve. If we’re not, the tired tropes become a calcified status quo which supports a fortunate few and quashes the concerns of the unrepresented. The models are always on a time-lag, optimised for past behaviour hoping to hold good in an uncertain future.</p>
<p>The most likely outcomes are always conditional on the underlying distribution and it is somewhat of an art how to properly specify each probability model: how to choose the dimensions to measure, which interaction effects are important, the parameters of the model? Your next action might be predictable if the modeler can adjust their expectations for the appropriate features, but even then you get lost in the mileau, swept up among the many. Even in the era of Big-Data, predictability is no substitute for understanding, no threat to individuality. The dynamics of the market move on and a once effective models decay… you’re a moving target. Keep moving, drag the models forward.</p>
<ul>
<li><a href="../../../notebooks/revealed_preferences_mcfadden_BART.ipynb" download="">Download Jupyter Notebook: MLE, Utility and Discrete Choice Models</a></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>