{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Aalen's Dynamic Path Model\"\n",
        "subtitle: \"Causal Inference with Time Varying Effects in PyMC\"\n",
        "categories: [\"path-models\", \"sem\", \"causal inference\"]\n",
        "keep-ipynb: true\n",
        "self-contained: true\n",
        "draft: true\n",
        "toc: true\n",
        "execute: \n",
        "  freeze: auto \n",
        "  execute: true\n",
        "jupyter: applied-bayesian-regression-modeling-env\n",
        "image: 'forking_paths.jpg'\n",
        "author:\n",
        "    - url: https://nathanielf.github.io/\n",
        "    - affiliation: PyMC dev\n",
        "citation: true\n",
        "---\n",
        "\n",
        "\n",
        "hello world\n"
      ],
      "id": "96ae72a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pymc as pm\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import arviz as az\n",
        "import pytensor.tensor as pt\n",
        "from scipy.interpolate import BSpline"
      ],
      "id": "ec819b31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you look to Odysseus on the morning the gates of Troy fell, he is well set up for a happy journey home. He is the architect of victory, his ships are loaded with spoils, and the wind is at his back. Yet, an odyssey can't be completed in a single day and conclusions drawn on the outset rarely survive journey's end. \n",
        "\n",
        "When we rely on static snapshots, like a single blood draw or a particular sales campaign, we are essentially watching Odysseus board his ship and guessing how the story ends. We ignore the __consequences emerging in time.__\n"
      ],
      "id": "78a98e50"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(\"aalen_simdata.csv\")\n",
        "df = df[['subject', 'x', 'dose', 'M', 'start', 'stop', 'event']]\n",
        "df.head()"
      ],
      "id": "fe1e496f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.groupby(['x', 'dose'])[['event', 'M']].agg(['mean', 'sum'])"
      ],
      "id": "f891dc4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | code-fold: true\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Derive subject-level info for ordering\n",
        "subject_info = (\n",
        "    df.groupby('subject')\n",
        "      .agg(\n",
        "          x=('x', 'first'),\n",
        "          max_stop=('stop', 'max')\n",
        "      )\n",
        "      .sort_values(['x', 'max_stop'])\n",
        ")\n",
        "\n",
        "subjects = subject_info.index.tolist()\n",
        "subject_to_y = {s: i for i, s in enumerate(subjects)}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 0.1 * len(subjects)))\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    y = subject_to_y[row['subject']]\n",
        "    \n",
        "    color = 'tab:blue' if row['x'] == 1 else 'tab:orange'\n",
        "    \n",
        "    ax.hlines(\n",
        "        y=y,\n",
        "        xmin=row['start'],\n",
        "        xmax=row['stop'],\n",
        "        color=color,\n",
        "        linewidth=3\n",
        "    )\n",
        "    \n",
        "    if row['event'] == 1:\n",
        "        ax.plot(\n",
        "            row['stop'],\n",
        "            y,\n",
        "            marker='o',\n",
        "            color='red',\n",
        "            markersize=6,\n",
        "            zorder=3\n",
        "        )\n",
        "\n",
        "# Axis formatting\n",
        "ax.set_yticks(range(len(subjects)))\n",
        "ax.set_yticklabels(subjects)\n",
        "ax.set_xlabel(\"Time\")\n",
        "ax.set_ylabel(\"Subject\")\n",
        "\n",
        "# Visual separation between treatment groups\n",
        "x0_count = (subject_info['x'] == 0).sum()\n",
        "ax.axhline(x0_count - 0.5, color='black', linestyle='--', linewidth=1)\n",
        "\n",
        "# Legend\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "legend_elements = [\n",
        "    Line2D([0], [0], color='tab:blue', lw=3, label='x = 1'),\n",
        "    Line2D([0], [0], color='tab:orange', lw=3, label='x = 0'),\n",
        "    Line2D([0], [0], marker='o', color='red', lw=0, label='Event', markersize=6)\n",
        "]\n",
        "\n",
        "ax.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "ax.set_title(\"Subject Timelines Ordered by Treatment Level\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "id": "1116047c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation\n"
      ],
      "id": "2932ed50"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def prepare_aalen_dpa_data(\n",
        "    df,\n",
        "    subject_col=\"subject\",\n",
        "    start_col=\"start\",\n",
        "    stop_col=\"stop\",\n",
        "    event_col=\"event\",\n",
        "    x_col=\"x\",\n",
        "    m_col=\"M\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Prepare Andersen–Gill / Aalen dynamic path data for PyMC.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Long-format start–stop survival data\n",
        "    subject_col : str\n",
        "        Subject identifier\n",
        "    start_col, stop_col : str\n",
        "        Interval boundaries\n",
        "    event_col : str\n",
        "        Event indicator (0/1)\n",
        "    x_col : str\n",
        "        Exposure / treatment\n",
        "    m_col : str\n",
        "        Mediator measured at interval start\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        Dictionary of numpy arrays ready for PyMC\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 1. Basic quantities\n",
        "    # -------------------------------------------------\n",
        "    df[\"dt\"] = df[stop_col] - df[start_col]\n",
        "\n",
        "    if (df[\"dt\"] <= 0).any():\n",
        "        raise ValueError(\"Non-positive interval lengths detected.\")\n",
        "\n",
        "    N = df[event_col].astype(int).values\n",
        "    Y = np.ones(len(df), dtype=int)  # Andersen–Gill at-risk indicator\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 2. Time-bin indexing (piecewise-constant effects)\n",
        "    # -------------------------------------------------\n",
        "    bins = (\n",
        "        df[[start_col, stop_col]]\n",
        "        .drop_duplicates()\n",
        "        .sort_values([start_col, stop_col])\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    bins[\"bin_idx\"] = np.arange(len(bins))\n",
        "\n",
        "    df = df.merge(\n",
        "        bins,\n",
        "        on=[start_col, stop_col],\n",
        "        how=\"left\",\n",
        "        validate=\"many_to_one\"\n",
        "    )\n",
        "\n",
        "    bin_idx = df[\"bin_idx\"].values\n",
        "    n_bins = bins.shape[0]\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 3. Center covariates (important for Aalen models)\n",
        "    # -------------------------------------------------\n",
        "    df[\"x_c\"] = df[x_col]\n",
        "    df[\"m_c\"] = df[m_col] - df[m_col].mean()\n",
        "\n",
        "    x = df[\"x_c\"].values\n",
        "    m = df[\"m_c\"].values\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 4. Predictable mediator (lag within subject)\n",
        "    # -------------------------------------------------\n",
        "    df = df.sort_values([subject_col, start_col])\n",
        "\n",
        "    df[\"m_lag\"] = (\n",
        "        df.groupby(subject_col)[\"m_c\"]\n",
        "          .shift(1)\n",
        "          .fillna(0.0)\n",
        "    )\n",
        "\n",
        "    m_lag = df[\"m_lag\"].values\n",
        "\n",
        "    df[\"I_low\"]  = (df[\"dose\"] == \"low\").astype(int)\n",
        "    df[\"I_high\"] = (df[\"dose\"] == \"high\").astype(int)\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # 5. Assemble output\n",
        "    # -------------------------------------------------\n",
        "    data = {\n",
        "        \"bins\": bins,     # useful for plotting\n",
        "        \"df_long\": df     # optional: debugging / inspection\n",
        "    }\n",
        "\n",
        "    return data\n"
      ],
      "id": "6a84f2b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = prepare_aalen_dpa_data(df)\n",
        "df_long = data['df_long']\n",
        "df_long[['subject', 'x', 'dose', 'M', 'event', 'dt', 'bin_idx']].head(14)"
      ],
      "id": "c007ef20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def create_bspline_basis(n_bins, n_knots=10, degree=3):\n",
        "    \"\"\"\n",
        "    Create B-spline basis functions for smooth time-varying effects.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    n_bins : int\n",
        "        Number of time bins\n",
        "    n_knots : int\n",
        "        Number of internal knots (fewer = smoother)\n",
        "    degree : int\n",
        "        Degree of spline (3 = cubic, recommended)\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    basis : np.ndarray\n",
        "        Matrix of shape (n_bins, n_basis) with basis function values\n",
        "    \"\"\"\n",
        "    # Create knot sequence\n",
        "    # Internal knots equally spaced across time range\n",
        "    internal_knots = np.linspace(0, n_bins-1, n_knots)\n",
        "    \n",
        "    # Add boundary knots (repeated degree+1 times for clamped spline)\n",
        "    knots = np.concatenate([\n",
        "        np.repeat(internal_knots[0], degree),\n",
        "        internal_knots,\n",
        "        np.repeat(internal_knots[-1], degree)\n",
        "    ])\n",
        "    \n",
        "    # Number of basis functions\n",
        "    n_basis = len(knots) - degree - 1\n",
        "    \n",
        "    # Evaluate each basis function at each time point\n",
        "    t = np.arange(n_bins, dtype=float)\n",
        "    basis = np.zeros((n_bins, n_basis))\n",
        "    \n",
        "    for i in range(n_basis):\n",
        "        # Create coefficient vector (indicator for basis i)\n",
        "        coef = np.zeros(n_basis)\n",
        "        coef[i] = 1.0\n",
        "        \n",
        "        # Evaluate B-spline\n",
        "        spline = BSpline(knots, coef, degree, extrapolate=False)\n",
        "        basis[:, i] = spline(t)\n",
        "    \n",
        "    return basis\n",
        "\n",
        "n_knots = 10\n",
        "n_bins = data['bins'].shape[0]\n",
        "basis = create_bspline_basis(n_bins, n_knots=n_knots, degree=3)\n",
        "n_cols = basis.shape[1]\n",
        "basis_df = pd.DataFrame(basis, columns=[f'feature_{i}' for i in range(n_cols)])\n",
        "basis_df.head(10)"
      ],
      "id": "becf0000",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | output: false\n",
        "\n",
        "def make_model(data, basis, sample=True, observed=True): \n",
        "    df_long = data['df_long'].copy()\n",
        "    n_basis = basis.shape[1]\n",
        "    n_obs = data['df_long'].shape[0]\n",
        "    time_bins = data['bins']['bin_idx'].values\n",
        "    b = df_long['bin_idx']\n",
        "\n",
        "    observed_mediator = df_long[\"m_c\"].values\n",
        "    observed_events = df_long['event'].astype(int).values\n",
        "    observed_treatment = df_long['x'].astype(int).values\n",
        "    observed_mediator_lag = df_long['m_lag'].values\n",
        "\n",
        "    coords = {'tv': ['intercept', 'direct', 'mediator'], \n",
        "            'splines': ['spline_f_{i}' for i in range(n_basis)], \n",
        "            'obs': range(n_obs), \n",
        "            'time_bins': time_bins}\n",
        "\n",
        "    with pm.Model(coords=coords) as aalen_dpa_model:\n",
        "\n",
        "        trt = pm.Data(\"trt\", observed_treatment, dims=\"obs\")\n",
        "        med = pm.Data(\"mediator\", observed_mediator, dims=\"obs\")\n",
        "        med_lag = pm.Data(\"mediator_lag\", observed_mediator_lag, dims=\"obs\")\n",
        "        events = pm.Data(\"events\", observed_events, dims=\"obs\")\n",
        "        I_low  = pm.Data(\"I_low\",  df_long[\"I_low\"].values,  dims=\"obs\")\n",
        "        I_high = pm.Data(\"I_high\", df_long[\"I_high\"].values, dims=\"obs\")\n",
        "        dt = pm.Data(\"duration\", df_long['dt'].values, dims='obs')\n",
        "        ## because our long data format has a cell per obs\n",
        "        at_risk = pm.Data(\"at_risk\", np.ones(len(observed_events)), dims=\"obs\")\n",
        "        basis_ = pm.Data(\"basis\", basis, dims=('time_bins', 'splines') )\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 1. B-spline coefficients for HAZARD model\n",
        "        # -------------------------------------------------\n",
        "        # Prior on spline coefficients\n",
        "        # Smaller sigma = less wiggliness\n",
        "        # Random Walk 1 (RW1) Prior for coefficients\n",
        "        # This is the Bayesian version of the smoothing penalty in R's 'mgcv' or 'timereg'\n",
        "        sigma_smooth = pm.Exponential(\"sigma_smooth\", [1, 1, 1], dims='tv')\n",
        "        beta_raw = pm.Normal(\"beta_raw\", 0, 1, dims=('splines', 'tv'))\n",
        "\n",
        "        # Cumulative sum makes it a Random Walk\n",
        "        # This ensures coefficients evolve smoothly over time\n",
        "        coef_alpha = pm.Deterministic(\"coef_alpha\", pt.cumsum(beta_raw * sigma_smooth, axis=0), dims=('splines', 'tv'))\n",
        "\n",
        "        # Construct smooth time-varying functions\n",
        "        alpha_0_t = pt.dot(basis_, coef_alpha[:, 0])\n",
        "        alpha_1_t = pt.dot(basis_, coef_alpha[:, 1])\n",
        "        alpha_2_t = pt.dot(basis_, coef_alpha[:, 2])\n",
        "        \n",
        "        # -------------------------------------------------\n",
        "        # 2. B-spline coefficients for MEDIATOR model\n",
        "        # -------------------------------------------------\n",
        "        sigma_beta_smooth = pm.Exponential(\"sigma_beta_smooth\", 0.1)\n",
        "        beta_raw = pm.Normal(\"beta_raw_m\", 0, 1, dims=('splines'))\n",
        "        coef_beta = pt.cumsum(beta_raw * sigma_beta_smooth)\n",
        "        \n",
        "        beta_t = pt.dot(basis_, coef_beta)\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 3. Mediator model (A path: x → M)\n",
        "        # -------------------------------------------------\n",
        "        sigma_m = pm.HalfNormal(\"sigma_m\", 1.0)\n",
        "        \n",
        "        # Autoregressive component\n",
        "        rho = pm.Beta(\"rho\", 2, 2)\n",
        "        \n",
        "        mu_m = beta_t[b] * trt + rho * med_lag\n",
        "\n",
        "        pm.Normal(\n",
        "            \"obs_m\",\n",
        "            mu=mu_m,\n",
        "            sigma=sigma_m,\n",
        "            observed=med,\n",
        "            dims='obs'\n",
        "        )\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 4. Hazard model (direct + B path)\n",
        "        # -------------------------------------------------\n",
        "        beta_low  = pm.Normal(\"beta_low\",  0, 0.1)\n",
        "        beta_high = pm.Normal(\"beta_high\", 0, 0.1)\n",
        "        # Log-additive hazard\n",
        "        log_lambda_t = (alpha_0_t[b] \n",
        "                        + alpha_1_t[b] * trt # direct effect\n",
        "                        + alpha_2_t[b] * med  # mediator effect\n",
        "                        + beta_low  * I_low\n",
        "                        + beta_high * I_high\n",
        "        )\n",
        "        \n",
        "        # Expected number of events\n",
        "        time_at_risk = at_risk * dt\n",
        "        Lambda = time_at_risk * pm.math.log1pexp(log_lambda_t)\n",
        "\n",
        "        if observed:\n",
        "            pm.Poisson(\n",
        "                \"obs_event\",\n",
        "                mu=Lambda,\n",
        "                observed=events, \n",
        "                dims='obs'\n",
        "            )\n",
        "        else: \n",
        "            pm.Poisson(\n",
        "                \"obs_event\",\n",
        "                mu=Lambda,\n",
        "                dims='obs'\n",
        "            )\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 5. Causal path effects\n",
        "        # -------------------------------------------------\n",
        "        # Store time-varying coefficients\n",
        "        pm.Deterministic(\"alpha_0_t\", alpha_0_t, dims='time_bins')\n",
        "        pm.Deterministic(\"alpha_1_t\", alpha_1_t, dims='time_bins')  # direct effect\n",
        "        pm.Deterministic(\"alpha_2_t\", alpha_2_t, dims='time_bins')  # B path\n",
        "        pm.Deterministic(\"beta_t\", beta_t, dims='time_bins')        # A path\n",
        "        \n",
        "        # Cumulative direct effect\n",
        "        cum_de = pm.Deterministic(\n",
        "            \"tv_direct_effect\",\n",
        "            alpha_1_t, \n",
        "            dims='time_bins'\n",
        "        )\n",
        "\n",
        "        # Cumulative indirect effect (product of paths)\n",
        "        cum_ie = pm.Deterministic(\n",
        "            \"tv_indirect_effect\",\n",
        "            beta_t * alpha_2_t, \n",
        "            dims='time_bins'\n",
        "        )\n",
        "\n",
        "        # Total effect\n",
        "        cum_te = pm.Deterministic(\n",
        "            \"tv_total_effect\",\n",
        "            cum_de + cum_ie,\n",
        "            dims='time_bins'\n",
        "        )\n",
        "\n",
        "        pm.Deterministic('tv_baseline_hazard', pm.math.log1pexp(alpha_0_t), \n",
        "            dims='time_bins')\n",
        "\n",
        "        pm.Deterministic('tv_hazard_with_exposure', pm.math.log1pexp(alpha_0_t + alpha_1_t), \n",
        "            dims='time_bins')\n",
        "\n",
        "        pm.Deterministic(\n",
        "        \"tv_RR\",\n",
        "        pm.math.log1pexp(alpha_0_t + alpha_1_t) /\n",
        "        pm.math.log1pexp(alpha_0_t),\n",
        "        dims=\"time_bins\"\n",
        "        )\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # 6. Sample\n",
        "        # -------------------------------------------------\n",
        "        if sample:\n",
        "            idata = pm.sample_prior_predictive()\n",
        "            idata.extend(pm.sample(\n",
        "                draws=2000,\n",
        "                tune=2000,\n",
        "                target_accept=0.95,\n",
        "                chains=4,\n",
        "                nuts_sampler=\"numpyro\",\n",
        "                random_seed=42,\n",
        "                init=\"adapt_diag\", \n",
        "                idata_kwargs={\"log_likelihood\": True}\n",
        "            ))\n",
        "            idata.extend(pm.sample_posterior_predictive(idata))\n",
        "    \n",
        "    return aalen_dpa_model, idata\n",
        "\n",
        "basis = create_bspline_basis(n_bins, n_knots=12, degree=3)\n",
        "aalen_dpa_model, idata_aalen =  make_model(data, basis)"
      ],
      "id": "3a6b270a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pm.model_to_graphviz(aalen_dpa_model)"
      ],
      "id": "20550a8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "models = {}\n",
        "idatas = {}\n",
        "for i in range(4, 15, 2):\n",
        "    basis = create_bspline_basis(n_bins, n_knots=i, degree=3)\n",
        "    aalen_dpa_model, idata = make_model(data, basis)\n",
        "    models[i] = aalen_dpa_model\n",
        "    idatas[f\"splines_{i}\"] = idata\n",
        "\n",
        "compare_df = az.compare(idatas, var_name='obs_event')\n",
        "az.plot_compare(compare_df, figsize=(8, 6), plot_ic_diff=True)"
      ],
      "id": "a92c2e8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](spline_loo_comparison.png)\n"
      ],
      "id": "b56362ed"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# | eval: false\n",
        "\n",
        "ax = az.plot_forest([idatas[k] for k in idatas.keys()], combined=True, var_names=['tv_direct_effect'], model_names=idatas.keys(), coords={'time_bins': [180, 182, 182, 183, 184, 185, 186, 187, 188]}, \n",
        "figsize=(12, 10),  r_hat=True)\n",
        "ax[0].set_title(\"Time Vary Direct Effects \\n Comparing Models on Final Time Intervals\", fontsize=15)\n",
        "ax[0].set_ylabel(\"Nth Time Interval\", fontsize=15)\n",
        "fig = ax[0].figure\n",
        "fig.savefig('forest_plot_comparing_tv_direct.png')"
      ],
      "id": "dd82e7a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](forest_plot_comparing_tv_direct.png)\n"
      ],
      "id": "1d2cc4ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "az.plot_trace(idata_aalen, var_names=['tv_direct_effect', 'tv_indirect_effect', 'tv_total_effect', 'beta_high', 'beta_low'], divergences=False);\n",
        "plt.tight_layout()\n"
      ],
      "id": "678f367a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vars_to_plot = ['tv_direct_effect', 'tv_indirect_effect', 'tv_total_effect']\n",
        "labels = ['Time varying Direct Effect', 'Time varying Indirect Effect', 'Time varying Total Effect']\n",
        "\n",
        "def plot_effects(idata, vars_to_plot, labels, scale=\"Log Hazard Ratio Scale\"):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(20, 10))\n",
        "    color='teal'\n",
        "    if scale != \"Log Hazard Ratio Scale\":\n",
        "        color='darkred'\n",
        "\n",
        "    for i, var in enumerate(vars_to_plot):\n",
        "        # 1. Extract the posterior samples for this variable\n",
        "        # Shape will be (chain * draw, time)\n",
        "        post_samples = az.extract(idata, var_names=[var]).values.T\n",
        "        \n",
        "        # 2. Calculate the mean and the 94% HDI across the chains/draws\n",
        "        mean_val = post_samples.mean(axis=0)\n",
        "        hdi_val = az.hdi(post_samples, hdi_prob=0.94) # Returns [time, 2] array\n",
        "        \n",
        "        # 3. Plot the Mean line\n",
        "        x_axis = np.arange(len(mean_val))\n",
        "        axs[i].plot(x_axis, mean_val, label=labels[i], color=color, lw=2)\n",
        "        \n",
        "        # 4. Plot the Shaded HDI region\n",
        "        axs[i].fill_between(x_axis, hdi_val[:, 0], hdi_val[:, 1], color=color, alpha=0.2, label='94% HDI')\n",
        "        \n",
        "        # Formatting\n",
        "        axs[i].set_title(labels[i])\n",
        "        axs[i].legend()\n",
        "        axs[i].grid(alpha=0.3)\n",
        "        axs[i].set_ylabel(scale)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "plot_effects(idata_aalen, vars_to_plot, labels);"
      ],
      "id": "b25cbd5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vars_to_plot = ['tv_baseline_hazard', 'tv_hazard_with_exposure', 'tv_RR']\n",
        "labels = ['Time varying Baseline Hazard', 'Time varying Hazard + Exposure', 'Time varying RR']\n",
        "plot_effects(idata_aalen, vars_to_plot, labels, scale='Hazard Scale');"
      ],
      "id": "50d47d14",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "applied-bayesian-regression-modeling-env",
      "language": "python",
      "display_name": "applied-bayesian-regression-modeling-env",
      "path": "/Users/nathanielforde/Library/Jupyter/kernels/applied-bayesian-regression-modeling-env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}