{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"The Condorcet Jury Theorem and Democratic Rationality\"\n",
        "subtitle: \"Sensitivity Analysis of Failure Conditions\"\n",
        "categories: [\"theory\", \"simulation\", \"causal inference\", \"sensitivity analysis\"]\n",
        "keep-ipynb: true\n",
        "self-contained: true\n",
        "draft: true\n",
        "toc: true\n",
        "execute: \n",
        "  freeze: auto \n",
        "  execute: true\n",
        "  eval: true\n",
        "jupyter: applied-bayesian-regression-modeling-env\n",
        "image: 'evolving_dag.png'\n",
        "author:\n",
        "    - url: https://nathanielf.github.io/\n",
        "    - affiliation: PyMC dev\n",
        "citation: true\n",
        "---\n",
        "\n",
        "\n",
        "# The Legibility Trap: Contemptible Familiarity\n",
        "\n",
        "Decision making in the modern corporation has to be seen to be believed. Arguably, a smooth running machine for making decisions to game the market. In reality it is a hodge podge of salves for making the investor class feel safe, and C-suites feel in control. \n",
        "\n",
        "To the analyst and the private equity partner, \"unfamiliarity\" is unquantifiable risk. They demand a recognizable org chart, a standardized \"Agile\" workflow, and a set of \"Core Values\" that could be swapped between a pet-food startup and a sovereign wealth fund without anyone noticing. __This is the cult of Legibility__. Borrowing from James C. Scott’s _Seeing Like a State_, we see that when central authorities cannot understand a complex, organic system, they flatten it. They replace the wild, high-information \"forest\" of human talent with a \"plantation\" of identical, predictable units.\n",
        "\n",
        "But this familiarity breeds a systemic contempt for reality. When you optimize for the gaze of the outsider, you perform a cognitive lobotomy on your own workforce. In our quest for \"alignment\" or adherence to irrelevant standards, we destroy the only thing that makes a group smarter than an individual: the generative friction of our differences. The \"miracle\" of collective intelligence is a generative process. It requires that we be wrong in different directions so that, in the aggregate, we might be right. By smoothing out the \"noise\" of individual culture and opinion, we break the statistical engine that makes democracy and decentralization work. By smoothing out the \"noise\" of individual culture and opinion, we break the statistical engine of collective intelligence: The Condorcet Jury Theorem.\n",
        "\n",
        "## Do as I say, Not what I do.\n",
        "\n",
        "Investors are the world's most fervent believers in the power of diversification. They know that to survive a volatile market, they must hedge their bets across uncorrelated assets. While the investor hedges in the aggregate, they force the subordinate company to appear as a single, comparable unit on a spreadsheet. They demand that the company eliminate internal variance. They want the firm to be \"aligned,\" \"standardized,\" and \"legible.\" In doing so, they strip the company of the very same diversification they rely on for their portfolio.\n",
        "\n",
        "The Condorcet Jury Theorem (CJT) is the mathematical foundation of this diversification. It suggests that if you have a group of independent individuals who are each slightly more likely than not to be right ($p > 0.5$), the probability of the majority being correct approaches 100% as the group size grows. There is real value in diversity when deployed well. But it's brittle and corporate best practice is uniquely designed to break it. Let's see how this works.\n",
        "\n",
        "#### Setup\n",
        "\n",
        "To understand how legibility short-circuits learning, we need a way to build a \"company\" from the ground up and stress-test its decision-making. Our simulation function, simulate_jury_data, is the generative heart of this piece. It doesn’t just create random numbers; it creates a world where we can toggle the parameters of Generative Friction.\n"
      ],
      "id": "cada26c9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymc as pm\n",
        "import matplotlib.pyplot as plt\n",
        "import arviz as az\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configuration\n",
        "N_CASES = 50\n",
        "N_JURORS = 15\n",
        "JURY_SIZES = [3, 5, 7, 10, 15]\n",
        "BLOCK_ID = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])"
      ],
      "id": "6e5bf3da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Generation and the Ground Truth\n",
        "\n",
        "In a healthy system, learning happens in the gaps between different perspectives. But in a \"legible\" system, those gaps are closed. Our simulation allows us to model this across three dimensions\n"
      ],
      "id": "84904d29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def simulate_jury_data(n_cases, n_jurors, true_p=0.65, true_discrimination=0.5, \n",
        "                       block_id=None, true_sigma_block=1.2):\n",
        "    \"\"\"\n",
        "    Simulate jury voting data with optional block effects.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_cases : int\n",
        "        Number of cases to judge\n",
        "    n_jurors : int\n",
        "        Number of jurors\n",
        "    true_p : float\n",
        "        Average competence (probability of correct vote)\n",
        "    true_discrimination : float\n",
        "        Standard deviation of competence in logit space\n",
        "    block_id : array, optional\n",
        "        Group membership for each juror (enables faction effects)\n",
        "    true_sigma_block : float\n",
        "        Standard deviation of block effects\n",
        "        \n",
        "    Returns:\n",
        "    --------\n",
        "    votes : (n_cases, n_jurors) array\n",
        "        Binary voting matrix\n",
        "    p_jurors : (n_jurors,) array\n",
        "        True competence of each juror\n",
        "    true_states : (n_cases,) array\n",
        "        Ground truth for each case\n",
        "    \"\"\"\n",
        "    true_states = np.random.binomial(1, 0.5, n_cases)\n",
        "    \n",
        "    # Simulate heterogeneous competencies in logit space\n",
        "    logit_p_jurors = np.random.normal(\n",
        "        np.log(true_p / (1 - true_p)), \n",
        "        true_discrimination, \n",
        "        n_jurors\n",
        "    )\n",
        "    \n",
        "    # Add block effects if specified\n",
        "    if block_id is not None:\n",
        "        n_blocks = len(np.unique(block_id))\n",
        "        block_effect = np.random.normal(0.0, true_sigma_block, n_blocks)\n",
        "        logit_p_jurors += block_effect[block_id]\n",
        "    \n",
        "    p_jurors = 1 / (1 + np.exp(-logit_p_jurors))\n",
        "    \n",
        "    # Generate votes\n",
        "    votes = np.zeros((n_cases, n_jurors))\n",
        "    for i in range(n_cases):\n",
        "        for j in range(n_jurors):\n",
        "            prob = p_jurors[j] if true_states[i] == 1 else 1 - p_jurors[j]\n",
        "            votes[i, j] = np.random.binomial(1, prob)\n",
        "    \n",
        "    return votes, p_jurors, true_states\n",
        "\n",
        "# Generate our first dataset: simple case without blocks\n",
        "votes, p_jurors, true_states = simulate_jury_data(N_CASES, N_JURORS)\n",
        "\n",
        "print(f\"Data simulated: {N_CASES} cases, {N_JURORS} jurors\")\n",
        "print(f\"True average competence: {p_jurors.mean():.3f}\")\n",
        "majority = (votes.mean(axis=1) > 0.5) \n",
        "print(f\"Majority vote accuracy: {np.mean(majority == true_states):.3f}\")"
      ],
      "id": "8c89b630",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We've seen how our data generating process encodes a baseline degree of juror competence. On any yes/no question we've ensured that the average juror has $(p \\sim N(.65, \\sigma_{disc}))$ chance of getting the right answer. The $\\sigma_{disc}$ determines the range of individual skill in the population. We've then asked each juror to cast their vote on 50 decisions.\n",
        "\n",
        "## Part 2: Sensitivity to Prior Beliefs About Competence\n",
        "\n",
        "Our first sensitivity analysis asks: **how much do our conclusions depend on our prior beliefs about juror competence?**\n",
        "\n",
        "The Condorcet theorem assumes jurors are better than random (p > 0.5), but how confident should we be in this? Let's test four different prior specifications:\n"
      ],
      "id": "73a73fa2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define prior specifications\n",
        "prior_specs = {\n",
        "    'weakly_informative': {\n",
        "        'alpha': 3, 'beta': 2, \n",
        "        'desc': 'Weakly informative (centered at 0.6)'\n",
        "    },\n",
        "    'strong_competence': {\n",
        "        'alpha': 10, 'beta': 5, \n",
        "        'desc': 'Strong prior (p ~ 0.67)'\n",
        "    },\n",
        "    'barely_competent': {\n",
        "        'alpha': 6, 'beta': 5, \n",
        "        'desc': 'Skeptical prior (p ~ 0.55)'\n",
        "    },\n",
        "    'incompetent': {\n",
        "        'alpha': 5, 'beta': 10, \n",
        "        'desc': 'Incompetent prior (p ~ 0.33)'\n",
        "    },\n",
        "}"
      ],
      "id": "08d9c64e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll fit our base Condorcet model under each prior specification:\n",
        "\n",
        "### Model 1: The Classical Condorcet Jury Model\n",
        "\n",
        "Let $$T_i \\in \\{0,1\\}$$ denote the true state of case $$i = 1,\\dots,N$$, with\n",
        "$$\n",
        "T_i \\sim \\text{Bernoulli}(0.5).\n",
        "$$\n",
        "\n",
        "Each juror $j = 1,\\dots,J$ casts a binary vote $V_{ij} \\in \\{0,1\\}$.\n",
        "Conditioned on the truth, all jurors share a common probability of voting correctly:\n",
        "$$\n",
        "\\Pr(V_{ij} = T_i \\mid p) = p, \\qquad p > \\tfrac{1}{2}.\n",
        "$$\n",
        "\n",
        "Equivalently, the likelihood may be written as:\n",
        "$$\n",
        "V_{ij} \\mid T_i, p \\sim\n",
        "\\begin{cases}\n",
        "\\text{Bernoulli}(p) & \\text{if } T_i = 1, \\\\\n",
        "\\text{Bernoulli}(1-p) & \\text{if } T_i = 0.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "#### Structural Assumptions\n",
        "\n",
        "This model imposes three strong assumptions:\n",
        "\n",
        "1. **Exchangeability across jurors**: all jurors are equally competent.\n",
        "2. **Exchangeability across cases**: all cases are equally difficult.\n",
        "3. **Conditional independence**:\n",
        "$$\n",
        "V_{ij} \\perp V_{ik} \\mid T_i, p.\n",
        "$$\n",
        "\n",
        "These assumptions define the idealized world in which the Condorcet Jury Theorem applies.\n"
      ],
      "id": "04fa8bef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_base_condorcet_model(votes, prior_spec, n_cases=N_CASES):\n",
        "    \"\"\"\n",
        "    Fit basic Condorcet model with specified prior on competence.\n",
        "    \n",
        "    This model assumes:\n",
        "    - All jurors have identical competence p\n",
        "    - Votes are conditionally independent given the truth\n",
        "    - Equal prior probability for guilty/not guilty\n",
        "    \"\"\"\n",
        "    with pm.Model() as model:\n",
        "        # SENSITIVITY PARAMETER: Prior on competence\n",
        "        p = pm.Beta('p', alpha=prior_spec['alpha'], beta=prior_spec['beta'])\n",
        "        \n",
        "        # Latent true state of each case\n",
        "        true_state = pm.Bernoulli('true_state', p=0.5, shape=n_cases)\n",
        "        \n",
        "        # Voting probability depends on true state\n",
        "        vote_prob = pm.Deterministic('vote_prob', pm.math.switch(\n",
        "            pm.math.eq(true_state[:, None], 1), p, 1 - p\n",
        "        ))\n",
        "        \n",
        "        pm.Bernoulli('votes', p=vote_prob, observed=votes)\n",
        "        \n",
        "        # Posterior predictive: majority vote accuracy for different jury sizes\n",
        "        for size in [3, 7, 15]:\n",
        "            votes_sim = pm.Bernoulli(f'sim_votes_{size}', p=p, shape=size)\n",
        "            pm.Deterministic(\n",
        "                f'majority_correct_{size}',\n",
        "                pm.math.sum(votes_sim) > size / 2\n",
        "            )\n",
        "        \n",
        "        # Sample\n",
        "        idata = pm.sample_prior_predictive()\n",
        "        idata.extend(pm.sample(2000, tune=1000, random_seed=42,\n",
        "                              target_accept=0.95, return_inferencedata=True))\n",
        "        idata.extend(pm.sample_posterior_predictive(idata))\n",
        "    \n",
        "    return idata, model"
      ],
      "id": "423e6c3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prior Sensitivity in the Condorcet Model\n",
        "\n",
        "We retain the likelihood from the classical Condorcet model but introduce uncertainty\n",
        "about juror competence via a prior distribution:\n",
        "$$\n",
        "p \\sim \\text{Beta}(\\alpha, \\beta).\n",
        "$$\n",
        "\n",
        "No assumptions about independence or exchangeability are altered.\n",
        "Instead, this model makes explicit the epistemic commitment that the Condorcet theorem leaves implicit: jurors are often assumed to be better than random *a priori*.\n",
        "\n",
        "#### Interpretation\n",
        "\n",
        "This modification does not change how votes are generated.\n",
        "It only affects how strongly we believe in democratic competence before observing data.\n",
        "\n",
        "If Condorcet-style aggregation fails under this model, the failure cannot be attributed to unrealistic priors — only to the structure of the voting process itself.\n"
      ],
      "id": "c328d0eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit under all prior specifications\n",
        "traces = {}\n",
        "for prior_name, spec in prior_specs.items():\n",
        "    print(f\"\\nFitting with {spec['desc']}...\")\n",
        "    idata, model = fit_base_condorcet_model(votes, spec)\n",
        "    traces[prior_name] = idata\n",
        "    traces[prior_name + '_model'] = model"
      ],
      "id": "22861c80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's examine how our prior beliefs influence predictions:\n"
      ],
      "id": "db8ff087"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def extract_estimates(traces, prior_specs, jury_sizes=[3, 7, 15], stage='prior'):\n",
        "    \"\"\"Extract majority accuracy estimates from traces.\"\"\"\n",
        "    ests = {}\n",
        "    for prior_name in prior_specs.keys():\n",
        "        estimates = []\n",
        "        for size in jury_sizes:\n",
        "            p = traces[prior_name][stage][f'majority_correct_{size}'].mean().item()\n",
        "            estimates.append(p)\n",
        "        ests[prior_name] = estimates\n",
        "    \n",
        "    return pd.DataFrame(\n",
        "        ests, \n",
        "        index=[f'Correct % for Majority of {s}' for s in jury_sizes]\n",
        "    )\n",
        "\n",
        "# Compare prior and posterior estimates\n",
        "prior_estimates = extract_estimates(traces, prior_specs, stage='prior')\n",
        "posterior_estimates = extract_estimates(traces, prior_specs, stage='posterior')\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PRIOR ESTIMATES\")\n",
        "print(\"=\"*70)\n",
        "print(prior_estimates)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"POSTERIOR ESTIMATES (AFTER SEEING DATA)\")\n",
        "print(\"=\"*70)\n",
        "print(posterior_estimates)"
      ],
      "id": "aa5ab1b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the shift from prior to posterior\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
        "\n",
        "for prior_name in prior_specs.keys():\n",
        "    axs[0].plot(prior_estimates.index, prior_estimates[prior_name], \n",
        "                label=prior_name, marker='o')\n",
        "    axs[1].plot(posterior_estimates.index, posterior_estimates[prior_name], \n",
        "                label=prior_name, marker='o')\n",
        "\n",
        "axs[0].legend()\n",
        "axs[1].legend()\n",
        "axs[0].set_title(\"Prior Beliefs About Majority Accuracy\")\n",
        "axs[1].set_title(\"Posterior Beliefs (After Observing Data)\")\n",
        "axs[0].set_ylabel(\"Probability of Correct Majority Decision\")\n",
        "axs[1].set_ylabel(\"Probability of Correct Majority Decision\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "07bf488c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key insight**: Strong prior beliefs about incompetence, the data updates our beliefs away from the truth. You cannot avoid the requirement of minimum competence in the jury pool.\n",
        "\n",
        "## Part 3: Individual Differences in Competence\n",
        "\n",
        "The base Condorcet model assumes all jurors are identically competent. In reality, people vary in expertise, attention, and judgment. Let's model **heterogeneity** in juror competence.\n",
        "\n",
        "### The Hierarchical Model\n",
        "\n",
        "We'll use a hierarchical model where individual competencies are drawn from a population distribution. The key sensitivity parameter is σ (discrimination): how much do jurors differ?\n",
        "\n",
        "#### Heterogeneous Juror Competence\n",
        "\n",
        "We now relax the assumption that all jurors are equally competent.\n",
        "\n",
        "Each juror $j$ is assigned an individual probability of voting correctly:\n",
        "$$\n",
        "\\text{logit}(p_j) = \\mu + \\sigma z_j, \\qquad z_j \\sim \\mathcal{N}(0,1).\n",
        "$$\n",
        "\n",
        "### Collapsing Bernoulli Votes to a Binomial Likelihood\n",
        "\n",
        "For a fixed juror $j$, define the number of agreements with the majority:\n",
        "$$\n",
        "A_j = \\sum_{i=1}^N \\mathbb{1}\\{V_{ij} = \\text{majority}_i\\}.\n",
        "$$\n",
        "\n",
        "Under the assumption that cases are exchangeable and votes are conditionally independent given $p_j$, we obtain the exact likelihood:\n",
        "\n",
        "$$\n",
        "A_j \\mid p_j \\sim \\text{Binomial}(N, p_j).\n",
        "$$\n",
        "\n",
        "This is not an approximation.\n",
        "It is the marginal likelihood obtained by integrating over $$N$$ independent Bernoulli trials:\n",
        "$$\n",
        "\\prod_{i=1}^N \\text{Bernoulli}(V_{ij} \\mid p_j)\n",
        "\\;\\Longrightarrow\\;\n",
        "\\text{Binomial}(A_j \\mid N, p_j).\n",
        "$$\n",
        "\n",
        "#### Structural Interpretation\n",
        "\n",
        "The Binomial likelihood relies on two assumptions:\n",
        "\n",
        "1. **Exchangeability across cases**\n",
        "2. **Sufficiency of the count statistic**\n",
        "\n",
        "Once jurors are treated as stable measurement instruments, their entire voting history becomes a single aggregated observation. This collapse will fail as soon as cases are no longer interchangeable.\n"
      ],
      "id": "a5d2b43b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_hierarchical_model(votes, n_jurors, discrimination_prior):\n",
        "    \"\"\"\n",
        "    Fit hierarchical model with individual variation in competence.\n",
        "    \n",
        "    Model structure:\n",
        "    - μ: population mean competence (in logit space)\n",
        "    - σ: population standard deviation (SENSITIVITY PARAMETER)\n",
        "    - Each juror has individual competence drawn from N(μ, σ)\n",
        "    \n",
        "    We use non-centered parameterization for better sampling.\n",
        "    \"\"\"\n",
        "    majority_votes = (votes.mean(axis=1) > 0.5).astype(int)\n",
        "    agreements_per_juror = np.array([\n",
        "        (votes[:, j] == majority_votes).sum() for j in range(n_jurors)\n",
        "    ])\n",
        "    \n",
        "    with pm.Model() as model:\n",
        "        # Population-level parameters\n",
        "        mu_logit_p = pm.Normal('mu_logit_p', mu=0.6, sigma=0.5)\n",
        "        \n",
        "        # KEY SENSITIVITY PARAMETER: individual discrimination\n",
        "        sigma_logit_p = pm.HalfNormal(\n",
        "            'sigma_logit_p', \n",
        "            sigma=discrimination_prior['sigma']\n",
        "        )\n",
        "        \n",
        "        # Non-centered parameterization: logit_p = μ + σ * z\n",
        "        z_juror = pm.Normal('z_juror', mu=0, sigma=1, shape=n_jurors)\n",
        "        logit_p_juror = pm.Deterministic(\n",
        "            'logit_p_juror', \n",
        "            mu_logit_p + sigma_logit_p * z_juror\n",
        "        )\n",
        "        p_juror = pm.Deterministic('p_juror', pm.math.invlogit(logit_p_juror))\n",
        "        \n",
        "        # Collapsed likelihood: count agreements with majority\n",
        "        pm.Binomial('agreements', n=N_CASES, p=p_juror, \n",
        "                   observed=agreements_per_juror)\n",
        "        \n",
        "        idata = pm.sample_prior_predictive()\n",
        "        idata.extend(pm.sample(1000, tune=2000, random_seed=42,\n",
        "                              target_accept=0.95, return_inferencedata=True,\n",
        "                              idata_kwargs={\"log_likelihood\": True}))\n",
        "        idata.extend(pm.sample_posterior_predictive(idata))\n",
        "    \n",
        "    return idata, model\n"
      ],
      "id": "02fb3eae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test three levels of discrimination\n",
        "discrimination_priors = {\n",
        "    'weak_discrimination': {\n",
        "        'sigma': 0.5, \n",
        "        'desc': 'Weak discrimination (σ ~ 0.25)'\n",
        "    },\n",
        "    'moderate_discrimination': {\n",
        "        'sigma': 1.0, \n",
        "        'desc': 'Moderate discrimination (σ ~ 0.5)'\n",
        "    },\n",
        "    'strong_discrimination': {\n",
        "        'sigma': 2.0, \n",
        "        'desc': 'Strong discrimination (σ ~ 2)'\n",
        "    },\n",
        "}\n",
        "\n",
        "traces_discrimination = {}\n",
        "for prior_name, spec in discrimination_priors.items():\n",
        "    print(f\"\\nFitting with {spec['desc']}...\")\n",
        "    idata, model = fit_hierarchical_model(votes, N_JURORS, spec)\n",
        "    traces_discrimination[prior_name] = idata\n",
        "    traces_discrimination[prior_name + '_model'] = model\n",
        "\n",
        "# Examine one of the fitted models\n",
        "az.summary(traces_discrimination['moderate_discrimination'])"
      ],
      "id": "fef02bd0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Posterior Predictive Checks\n",
        "\n",
        "To understand the implications of different discrimination levels, we need to simulate complete jury deliberations. We need to translate our individual voter's profile into votes. As before votes are generated as, but we have no longer directly modelled this outcome, so we derive implied votes through posterior predictive checks. \n",
        "$$\n",
        "V_{ij} \\mid T_i, p_j \\sim\n",
        "\\begin{cases}\n",
        "\\text{Bernoulli}(p_j) & \\text{if } T_i = 1, \\\\\n",
        "\\text{Bernoulli}(1-p_j) & \\text{if } T_i = 0.\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "#### Structural Consequences\n",
        "\n",
        "Conditional independence is preserved, but only after conditioning on individual competence:\n",
        "$$\n",
        "V_{ij} \\perp V_{ik} \\mid T_i, \\{p_j\\}.\n",
        "$$\n",
        "\n",
        "This model introduces inequality among jurors without introducing dependence.\n",
        "Heterogeneous competence alone does not violate the conditions of the Condorcet theorem. Here's our comprehensive PPC framework:\n"
      ],
      "id": "82f60f4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def simulate_votes_from_competence(p_juror, n_cases, truth=None):\n",
        "    \"\"\"Generate votes given juror competencies and ground truth.\"\"\"\n",
        "    n_jurors = len(p_juror)\n",
        "    if truth is None:\n",
        "        truth = np.random.binomial(1, 0.5, size=n_cases)\n",
        "    \n",
        "    votes = np.zeros((n_cases, n_jurors), dtype=int)\n",
        "    for i in range(n_cases):\n",
        "        for j in range(n_jurors):\n",
        "            prob = p_juror[j] if truth[i] == 1 else 1 - p_juror[j]\n",
        "            votes[i, j] = np.random.binomial(1, prob)\n",
        "    \n",
        "    return truth, votes\n",
        "\n",
        "\n",
        "def compute_diagnostics(votes, truth):\n",
        "    \"\"\"Compute suite of diagnostic metrics for jury performance.\"\"\"\n",
        "    majority = votes.mean(axis=1) > 0.5\n",
        "    \n",
        "    diagnostics = {\n",
        "        'majority_accuracy': np.mean(majority == truth),\n",
        "        'unanimity_rate': np.mean(\n",
        "            (votes.sum(axis=1) == 0) | (votes.sum(axis=1) == votes.shape[1])\n",
        "        ),\n",
        "        'juror_agreement': np.mean(votes == truth[:, None], axis=0),\n",
        "    }\n",
        "    \n",
        "    # Error correlation: do jurors make mistakes together?\n",
        "    errors = votes != truth[:, None]\n",
        "    if errors.var(axis=0).sum() > 0:\n",
        "        diagnostics['error_corr'] = np.corrcoef(errors.T)\n",
        "    else:\n",
        "        diagnostics['error_corr'] = np.zeros((votes.shape[1], votes.shape[1]))\n",
        "    \n",
        "    return diagnostics\n",
        "\n",
        "\n",
        "def majority_accuracy_by_size(votes, truth, jury_size):\n",
        "    \"\"\"Calculate accuracy for random sub-juries of given size.\"\"\"\n",
        "    n_cases, n_jurors = votes.shape\n",
        "    correct = np.zeros(n_cases, dtype=int)\n",
        "    \n",
        "    for i in range(n_cases):\n",
        "        jurors = np.random.choice(n_jurors, size=jury_size, replace=False)\n",
        "        majority = votes[i, jurors].mean() > 0.5\n",
        "        correct[i] = (majority == truth[i])\n",
        "    \n",
        "    return correct.mean()\n",
        "\n",
        "\n",
        "def run_ppc_analysis(idata, n_cases, truth, jury_sizes=JURY_SIZES):\n",
        "    \"\"\"Run comprehensive posterior predictive checks.\"\"\"\n",
        "    p_juror_samples = (idata.posterior['p_juror']\n",
        "                      .stack(sample=(\"chain\", \"draw\")).values)\n",
        "    n_jurors, n_samples = p_juror_samples.shape\n",
        "    \n",
        "    results = {\n",
        "        'majority_acc': np.zeros(n_samples),\n",
        "        'unanimity': np.zeros(n_samples),\n",
        "        'error_corr': np.zeros((n_samples, n_jurors, n_jurors)),\n",
        "        'accuracy_by_size': {k: np.zeros(n_samples) for k in jury_sizes}\n",
        "    }\n",
        "    \n",
        "    for s in range(n_samples):\n",
        "        _, votes = simulate_votes_from_competence(\n",
        "            p_juror_samples[:, s], n_cases, truth\n",
        "        )\n",
        "        diag = compute_diagnostics(votes, truth)\n",
        "        \n",
        "        results['majority_acc'][s] = diag['majority_accuracy']\n",
        "        results['unanimity'][s] = diag['unanimity_rate']\n",
        "        results['error_corr'][s] = diag['error_corr']\n",
        "        \n",
        "        for k in jury_sizes:\n",
        "            results['accuracy_by_size'][k][s] = (\n",
        "                majority_accuracy_by_size(votes, truth, k)\n",
        "            )\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "def summarize_ppc(ppc_results, jury_sizes=JURY_SIZES):\n",
        "    \"\"\"Create summary DataFrame from PPC results.\"\"\"\n",
        "    percentiles = [5, 50, 95]\n",
        "    summaries = []\n",
        "    \n",
        "    for k in jury_sizes:\n",
        "        summaries.append(np.percentile(\n",
        "            ppc_results['accuracy_by_size'][k], percentiles\n",
        "        ))\n",
        "    \n",
        "    df = pd.DataFrame(summaries).T\n",
        "    df.columns = [f'majority_accuracy_{k}' for k in jury_sizes]\n",
        "    df.index = [f'percentile_{p}' for p in percentiles]\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "def compare_prior_posterior(idata, n_cases, truth, jury_sizes=JURY_SIZES):\n",
        "    \"\"\"Compare prior and posterior predictive distributions.\"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for stage in ['prior', 'posterior']:\n",
        "        p_samples = (getattr(idata, stage)['p_juror']\n",
        "                    .stack(sample=(\"chain\", \"draw\")).values)\n",
        "        n_jurors, n_samples = p_samples.shape\n",
        "        \n",
        "        # Simplified PPC for comparison\n",
        "        stage_results = {k: np.zeros(n_samples) for k in jury_sizes}\n",
        "        for s in range(n_samples):\n",
        "            _, votes = simulate_votes_from_competence(\n",
        "                p_samples[:, s], n_cases, truth\n",
        "            )\n",
        "            for k in jury_sizes:\n",
        "                stage_results[k][s] = majority_accuracy_by_size(votes, truth, k)\n",
        "        \n",
        "        results[stage] = summarize_ppc({'accuracy_by_size': stage_results}, \n",
        "                                      jury_sizes)\n",
        "    \n",
        "    return pd.concat(results, names=['stage', 'percentile'])"
      ],
      "id": "d4d2d91a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's apply this framework. We'll focus on the moderate discrimination case as it's most realistic:\n"
      ],
      "id": "e7264581"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_prior_posterior_comparison(df, title=\"Majority Accuracy\"):\n",
        "    \"\"\"Plot prior vs posterior distributions.\"\"\"\n",
        "    x_values = JURY_SIZES\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    for stage, color in [('prior', 'blue'), ('posterior', 'red')]:\n",
        "        median = df.loc[(stage, 'percentile_50')]\n",
        "        low = df.loc[(stage, 'percentile_5')]\n",
        "        high = df.loc[(stage, 'percentile_95')]\n",
        "        \n",
        "        ax.plot(x_values, median, label=f'{stage.title()} Median', \n",
        "                color=color, marker='o')\n",
        "        ax.fill_between(x_values, low, high, color=color, alpha=0.2,\n",
        "                       label=f'{stage.title()} (5th-95th)')\n",
        "    \n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Number of Jurors')\n",
        "    ax.set_ylabel('Majority Accuracy')\n",
        "    ax.set_xticks(x_values)\n",
        "    ax.legend()\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Analyze the moderate discrimination case\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Analysis: {discrimination_priors['moderate_discrimination']['desc']}\")\n",
        "print('='*70)\n",
        "\n",
        "comparison = compare_prior_posterior(\n",
        "    traces_discrimination['moderate_discrimination'], \n",
        "    N_CASES, \n",
        "    true_states\n",
        ")\n",
        "\n",
        "print(comparison)\n",
        "plot_prior_posterior_comparison(\n",
        "    comparison, \n",
        "    title=\"Prior vs Posterior: Moderate Individual Variation\"\n",
        ")"
      ],
      "id": "6423f5d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pattern is consistent across all discrimination levels: the data updates our beliefs, and larger juries show higher accuracy. The key question is whether errors remain independent.\n",
        "\n",
        "\n",
        "## Error Correlation Analysis\n",
        "\n",
        "A critical assumption of Condorcet is **independence**: jurors make errors independently. Let's check this for our moderate discrimination model:\n"
      ],
      "id": "270a9025"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_error_correlation_heatmap(ppc_results, title=\"Error Correlation\"):\n",
        "    \"\"\"Plot mean error correlation matrix, handling NaN values properly.\"\"\"\n",
        "    all_corrs = ppc_results['error_corr']  # (n_samples, n_jurors, n_jurors)\n",
        "    \n",
        "    # Use nanmean to properly average across samples, ignoring NaNs\n",
        "    mean_corr = np.nanmean(all_corrs, axis=0)\n",
        "    \n",
        "    # For cells that are still NaN (all samples were NaN), replace with 0\n",
        "    mean_corr = np.nan_to_num(mean_corr, nan=0.0)\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    sns.heatmap(mean_corr, vmin=-0.3, vmax=0.3, cmap=\"coolwarm\",\n",
        "                square=True, cbar_kws={\"label\": \"Error correlation\"}, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "def summarize_error_correlation(ppc_results):\n",
        "    \"\"\"Extract summary statistics from error correlation matrices.\"\"\"\n",
        "    corr = ppc_results['error_corr']\n",
        "    n = corr.shape[1]\n",
        "    \n",
        "    off_diag = []\n",
        "    for s in range(corr.shape[0]):\n",
        "        mat = corr[s]\n",
        "        # Extract upper triangle (excluding diagonal)\n",
        "        upper_tri = mat[np.triu_indices(n, k=1)]\n",
        "        # Only include non-NaN values\n",
        "        valid_values = upper_tri[~np.isnan(upper_tri)]\n",
        "        if len(valid_values) > 0:\n",
        "            off_diag.extend(valid_values)\n",
        "    \n",
        "    off_diag = np.array(off_diag)\n",
        "    \n",
        "    if len(off_diag) == 0:\n",
        "        return {\n",
        "            'mean_off_diag': np.nan,\n",
        "            'sd_off_diag': np.nan,\n",
        "            'p95_abs_corr': np.nan,\n",
        "        }\n",
        "    \n",
        "    return {\n",
        "        'mean_off_diag': off_diag.mean(),\n",
        "        'sd_off_diag': off_diag.std(),\n",
        "        'p95_abs_corr': np.percentile(np.abs(off_diag), 95),\n",
        "    }\n",
        "\n",
        "\n",
        "ppc_moderate = run_ppc_analysis(\n",
        "    traces_discrimination['moderate_discrimination'], \n",
        "    N_CASES, \n",
        "    true_states\n",
        ")\n",
        "\n",
        "plot_error_correlation_heatmap(\n",
        "    ppc_moderate, \n",
        "    title=\"Error Correlation: Moderate Individual Variation\"\n",
        ")\n",
        "\n",
        "print(\"\\nError Correlation Summary:\")\n",
        "print(summarize_error_correlation(ppc_moderate))"
      ],
      "id": "6f010822",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key insight**: With heterogeneous competence alone, errors remain largely uncorrelated (mean ≈ 0). The Condorcet theorem's independence assumption holds—so far.\n",
        "\n",
        "# Part 4: Shared Case Difficulty\n",
        "\n",
        "Now we introduce a critical violation: **shared case-level effects**. Some cases are genuinely harder, causing even competent jurors to fail together.\n",
        "\n",
        "To properly explore this, we need to do posterior predictive sampling that includes case difficulty in the generative model. \n",
        "\n",
        "### Simulating Shared Case Shocks\n",
        "\n",
        "We now introduce case-level difficulty effects:\n",
        "$$\n",
        "\\delta_i \\sim \\mathcal{N}(0, \\sigma_{\\text{case}}).\n",
        "$$\n",
        "\n",
        "Votes are generated according to:\n",
        "$$\n",
        "\\text{logit}\\,\\Pr(V_{ij} = T_i)\n",
        "= \\alpha_j + \\delta_i.\n",
        "$$\n",
        "\n",
        "#### Structural Consequences\n",
        "\n",
        "Votes for the same case now share a common latent influence.\n",
        "As a result:\n",
        "$$\n",
        "V_{ij} \\not\\!\\perp V_{ik} \\mid T_i, \\alpha_j.\n",
        "$$\n",
        "\n",
        "Cases are no longer exchangeable, and the Binomial likelihood is no longer valid.\n",
        "This violation produces correlated errors across jurors and directly undermines\n",
        "the Condorcet theorem.\n"
      ],
      "id": "e32c8a4b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def ppc_with_case_difficulty(idata, model, n_cases_sim, sigma_case_values, \n",
        "                            true_states=None, n_draws=500):\n",
        "    \"\"\"\n",
        "    Posterior predictive checks with shared case-level difficulty effects.\n",
        "    \n",
        "    This properly samples from the posterior predictive distribution,\n",
        "    including uncertainty in juror competencies.\n",
        "    \"\"\"\n",
        "    if true_states is None:\n",
        "        true_states = np.random.binomial(1, 0.5, size=n_cases_sim)\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for sigma_case in sigma_case_values:\n",
        "        with model:\n",
        "            # Get posterior samples of logit_p_juror\n",
        "            logit_p_trace = idata.posterior['logit_p_juror']\n",
        "            n_jurors = logit_p_trace.shape[-1]\n",
        "            \n",
        "            # Sample from posterior predictive with case difficulty\n",
        "            # For each posterior sample, generate new votes with case effects\n",
        "            pm.set_data({'n_cases_ppc': n_cases_sim})\n",
        "            \n",
        "            # Case difficulty effects (shared across jurors)\n",
        "            delta_case = pm.Normal('delta_case', mu=0, sigma=sigma_case, \n",
        "                                  shape=n_cases_sim)\n",
        "            \n",
        "            # Generate votes for each case and juror\n",
        "            votes_list = []\n",
        "            for i in range(n_cases_sim):\n",
        "                truth_i = true_states[i]\n",
        "                sign = 1 if truth_i == 1 else -1\n",
        "                \n",
        "                # Competence + case difficulty\n",
        "                logit_p_case = sign * logit_p_trace + delta_case[i]\n",
        "                p_case = pm.math.sigmoid(logit_p_case)\n",
        "                \n",
        "                # This will be shape (chain, draw, n_jurors)\n",
        "                votes_i = pm.Bernoulli(f'votes_case_{i}', p=p_case)\n",
        "                votes_list.append(votes_i)\n",
        "            \n",
        "            # Sample from posterior predictive\n",
        "            ppc = pm.sample_posterior_predictive(\n",
        "                idata, \n",
        "                var_names=[f'votes_case_{i}' for i in range(n_cases_sim)] + ['delta_case'],\n",
        "                predictions=True,\n",
        "                random_seed=42\n",
        "            )\n",
        "        \n",
        "        # Reorganize votes into (sample, case, juror) array\n",
        "        n_samples = n_draws\n",
        "        votes_array = np.zeros((n_samples, n_cases_sim, n_jurors), dtype=int)\n",
        "        \n",
        "        for i in range(n_cases_sim):\n",
        "            votes_case = ppc.predictions[f'votes_case_{i}'].values\n",
        "            # Flatten chain and draw dimensions\n",
        "            votes_flat = votes_case.reshape(-1, n_jurors)[:n_samples]\n",
        "            votes_array[:, i, :] = votes_flat\n",
        "        \n",
        "        # Calculate diagnostics\n",
        "        acc = []\n",
        "        corrs = []\n",
        "        \n",
        "        for s in range(n_samples):\n",
        "            majority = votes_array[s].mean(axis=1) > 0.5\n",
        "            acc.append((majority == true_states).mean())\n",
        "            \n",
        "            errors = votes_array[s] != true_states[:, None]\n",
        "            if errors.var(axis=0).sum() > 0:\n",
        "                C = np.corrcoef(errors.T)\n",
        "                corrs.append(C)\n",
        "        \n",
        "        corrs = np.stack(corrs) if corrs else np.zeros((1, n_jurors, n_jurors))\n",
        "        off_diag = corrs[:, ~np.eye(n_jurors, dtype=bool)]\n",
        "        \n",
        "        results[sigma_case] = {\n",
        "            'accuracy': acc,\n",
        "            'mean_accuracy': np.mean(acc),\n",
        "            'error_corr': corrs,\n",
        "            'mean_corr': np.nanmean(off_diag),\n",
        "            'median_corr': np.nanmedian(off_diag),\n",
        "            'p95_abs_corr': np.nanpercentile(np.abs(off_diag), 95)\n",
        "        }\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "# Simpler approach: directly simulate from posterior samples\n",
        "def simple_case_difficulty_ppc(idata, n_cases_sim, sigma_case_values, \n",
        "                               true_states=None, n_draws=500):\n",
        "    \"\"\"\n",
        "    Simplified PPC that samples logit_p from posterior then adds case effects.\n",
        "    \"\"\"\n",
        "    if true_states is None:\n",
        "        true_states = np.random.binomial(1, 0.5, size=n_cases_sim)\n",
        "    \n",
        "    # Get posterior samples\n",
        "    logit_p_samples = (idata.posterior['logit_p_juror']\n",
        "                      .stack(sample=(\"chain\", \"draw\")).values)\n",
        "    n_jurors, total_samples = logit_p_samples.shape\n",
        "    \n",
        "    # Randomly select n_draws samples\n",
        "    sample_idx = np.random.choice(total_samples, size=n_draws, replace=False)\n",
        "    logit_p_samples = logit_p_samples[:, sample_idx]\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    for sigma_case in sigma_case_values:\n",
        "        votes_array = np.zeros((n_draws, n_cases_sim, n_jurors), dtype=int)\n",
        "        \n",
        "        for s in range(n_draws):\n",
        "            # Sample case difficulty effects\n",
        "            delta_case = np.random.normal(0, sigma_case, size=n_cases_sim)\n",
        "            \n",
        "            for i in range(n_cases_sim):\n",
        "                truth_i = true_states[i]\n",
        "                sign = 1 if truth_i == 1 else -1\n",
        "                \n",
        "                # Apply case difficulty to all jurors\n",
        "                logit_p_case = sign * logit_p_samples[:, s] + delta_case[i]\n",
        "                p_case = 1 / (1 + np.exp(-logit_p_case))\n",
        "                \n",
        "                votes_array[s, i, :] = np.random.binomial(1, p_case)\n",
        "        \n",
        "        # Calculate diagnostics\n",
        "        acc = []\n",
        "        corrs = []\n",
        "        \n",
        "        for s in range(n_draws):\n",
        "            majority = votes_array[s].mean(axis=1) > 0.5\n",
        "            acc.append((majority == true_states).mean())\n",
        "            \n",
        "            errors = votes_array[s] != true_states[:, None]\n",
        "            if errors.var(axis=0).sum() > 0:\n",
        "                C = np.corrcoef(errors.T)\n",
        "                corrs.append(C)\n",
        "        \n",
        "        corrs = np.stack(corrs) if corrs else np.zeros((1, n_jurors, n_jurors))\n",
        "        off_diag = corrs[:, ~np.eye(n_jurors, dtype=bool)]\n",
        "        \n",
        "        results[sigma_case] = {\n",
        "            'accuracy': acc,\n",
        "            'mean_accuracy': np.mean(acc),\n",
        "            'error_corr': corrs,\n",
        "            'mean_corr': np.nanmean(off_diag),\n",
        "            'median_corr': np.nanmedian(off_diag),\n",
        "            'p95_abs_corr': np.nanpercentile(np.abs(off_diag), 95)\n",
        "        }\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"IMPACT OF SHARED CASE DIFFICULTY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "sigma_values = [0.0, 0.2, 0.5, 1.0]\n",
        "case_diff_results = simple_case_difficulty_ppc(\n",
        "    traces_discrimination['weak_discrimination'],\n",
        "    n_cases_sim=N_CASES,\n",
        "    sigma_case_values=sigma_values,\n",
        "    true_states=true_states,\n",
        "    n_draws=500\n",
        ")\n",
        "\n",
        "for sigma in sigma_values:\n",
        "    res = case_diff_results[sigma]\n",
        "    print(f\"\\nσ_case = {sigma}\")\n",
        "    print(f\"  Mean majority accuracy: {res['mean_accuracy']:.3f}\")\n",
        "    print(f\"  Mean error correlation: {res['mean_corr']:.3f}\")\n",
        "    print(f\"  Median error correlation: {res['median_corr']:.3f}\")\n",
        "    print(f\"  95th %ile |correlation|: {res['p95_abs_corr']:.3f}\")"
      ],
      "id": "c3dc1088",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Critical insight**: As case difficulty variance increases (σ_case), error correlation rises dramatically. At σ = 1.0, jurors make correlated errors with mean correlation around 0.15-0.17. This violates the independence assumption and **degrades majority accuracy** even with competent jurors.\n",
        "\n",
        "# Part 5: The Complete Model\n",
        "\n",
        "Finally, we combine all sources of variation into a realistic hierarchical model:\n",
        "\n",
        "### Adding Group-Level (Block) Effects and Treatment Programmes\n",
        "\n",
        "Finally, we introduce block-level effects representing factions or information silos. We will also allow for the inclusion of a treatment programme. We might hope the latter drives the voter base towards better information. But we also risk driving the jury pool toward confidently wrong but shared opinions. \n",
        "\n",
        "Each juror belongs to a block $b(j)$, with:\n",
        "$$\n",
        "\\beta_{b(j)} \\sim \\mathcal{N}(0, \\sigma_{\\text{block}}).\n",
        "$$\n",
        "\n",
        "The full voting model becomes:\n",
        "$$\n",
        "\\text{logit}\\,\\Pr(V_{ij} = T_i)\n",
        "= \\alpha_j + \\beta_{b(j)} + \\delta_i + \\text{ treatment }*\\tau\n",
        "$$\n",
        "\n",
        "#### Structural Consequences\n",
        "\n",
        "Conditional independence between jurors fails even after conditioning on the truth:\n",
        "$$\n",
        "V_{ij} \\not\\!\\perp V_{ik}\n",
        "\\quad \\text{if } b(j) = b(k).\n",
        "$$\n",
        "\n",
        "Block effects induce structured error correlations that persist even in large juries.\n",
        "Aggregation no longer produces independent evidence.\n"
      ],
      "id": "63d9bfcf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate new data with block structure\n",
        "votes_blocked, p_jurors_blocked, true_states_blocked = simulate_jury_data(\n",
        "    N_CASES, N_JURORS, block_id=BLOCK_ID\n",
        ")\n",
        "\n",
        "def fit_full_model(votes, n_jurors, block_id, treatment_indicator,\n",
        "    use_treatment=0):\n",
        "    \"\"\"\n",
        "    Complete model with four sources of variation:\n",
        "    1. Individual skill (α_j)\n",
        "    2. Block/faction effects (β_block)\n",
        "    3. Case difficulty (δ_case)\n",
        "    4. Treatment Programme (tau)\n",
        "    \"\"\"\n",
        "    majority_votes = (votes.mean(axis=1) > 0.5).astype(int)\n",
        "    agreements_per_juror = np.array([\n",
        "        (votes[:, j] == majority_votes).sum() for j in range(n_jurors)\n",
        "    ])\n",
        "    \n",
        "    with pm.Model() as model:\n",
        "        # Individual skill\n",
        "        mu_alpha = pm.Normal(\"mu_alpha\", mu=0.0, sigma=0.5)\n",
        "        sigma_alpha = pm.Exponential(\"sigma_alpha\", lam=3.0)\n",
        "        alpha_raw = pm.Normal(\"alpha_raw\", 0.0, 1.0, shape=n_jurors)\n",
        "        alpha_j = pm.Normal(\n",
        "        \"alpha_j\",\n",
        "        mu=mu_alpha,\n",
        "        sigma=sigma_alpha,\n",
        "        shape=n_jurors,\n",
        "        )\n",
        "        \n",
        "        # Block effects (ideological factions, info silos)\n",
        "        n_blocks = len(np.unique(block_id))\n",
        "        sigma_block = pm.HalfNormal(\"sigma_block\", sigma=1.0)\n",
        "        block_effect = pm.Normal(\"block_effect\", mu=0.0, sigma=sigma_block, shape=n_blocks)\n",
        "        beta_block_j = block_effect[block_id]\n",
        "        \n",
        "        # Case difficulty (collapsed over cases)\n",
        "        mu_case = pm.Normal(\"mu_case\", mu=0.0, sigma=0.5)\n",
        "        sigma_case = pm.HalfNormal(\"sigma_case\", sigma=1.0)\n",
        "        delta_bar = pm.Normal(\"delta_bar\", mu=mu_case, \n",
        "                             sigma=sigma_case / pm.math.sqrt(N_CASES))\n",
        "\n",
        "        # -----------------------------\n",
        "        # Treatment effect (switchable)\n",
        "        # -----------------------------\n",
        "        tau = pm.Normal(\"tau\", mu=0, sigma=1.0, shape=N_JURORS)\n",
        "\n",
        "        # convert to tensors to avoid shape surprises\n",
        "        Z = pm.math.constant(treatment_indicator)\n",
        "        s = pm.math.constant(use_treatment)\n",
        "\n",
        "        treatment_term = pm.Deterministic('trt', s * Z * tau)\n",
        "        \n",
        "        # Combined model\n",
        "        logit_p_correct = ((alpha_j + beta_block_j + delta_bar) - treatment_term)\n",
        "        p_correct = pm.Deterministic(\"p_correct\", \n",
        "                                    pm.math.sigmoid(logit_p_correct))\n",
        "        \n",
        "        # Collapsed likelihood\n",
        "        pm.Binomial(\"agreements\", n=N_CASES, p=p_correct, \n",
        "                   observed=agreements_per_juror)\n",
        "        \n",
        "        idata = pm.sample(2000, tune=2000, target_accept=0.985, \n",
        "                         return_inferencedata=True, nuts_sampler='numpyro')\n",
        "    \n",
        "    return idata, model\n",
        "\n",
        "\n",
        "print(\"\\nFitting complete hierarchical model...\")\n",
        "idata_full, model_full = fit_full_model(votes_blocked, N_JURORS, BLOCK_ID,  treatment_indicator=np.zeros(N_JURORS), use_treatment=0)\n",
        "\n",
        "idata_full_trt, model_full_trt = fit_full_model(votes_blocked, N_JURORS, BLOCK_ID,  treatment_indicator=np.ones(N_JURORS), use_treatment=1)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPLETE MODEL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "full_summary = az.summary(idata_full, var_names=[\"mu_alpha\", \"sigma_alpha\", \"sigma_block\", \"mu_case\", \"sigma_case\", \"trt\"])\n",
        "\n",
        "full_trt_summary = az.summary(idata_full_trt, var_names=[\"mu_alpha\", \"sigma_alpha\", \"sigma_block\", \"mu_case\", \"sigma_case\", \"trt\"])\n",
        "\n",
        "summaries = pd.concat({'Full Model': full_summary, 'Full Model + Treatment': full_trt_summary})\n",
        "summaries"
      ],
      "id": "a6a32a3a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Posterior Predictive Checks for Complete Model\n",
        "\n",
        "Now let's examine how the complete model performs, including its error correlations:\n"
      ],
      "id": "28085187"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_ppc_full_model(idata, n_cases, true_states, block_id, \n",
        "                       jury_sizes=JURY_SIZES, n_draws=500):\n",
        "    \"\"\"\n",
        "    PPC for complete model including block and case effects.\n",
        "    Properly samples from posterior distribution.\n",
        "    \"\"\"\n",
        "    # Extract posterior samples\n",
        "    alpha_j = idata.posterior['alpha_j'].stack(sample=(\"chain\", \"draw\")).values\n",
        "    block_effect = idata.posterior['block_effect'].stack(sample=(\"chain\", \"draw\")).values\n",
        "    sigma_case = idata.posterior['sigma_case'].stack(sample=(\"chain\", \"draw\")).values\n",
        "    mu_case = idata.posterior['mu_case'].stack(sample=(\"chain\", \"draw\")).values\n",
        "    trt = idata.posterior['trt'].stack(sample=(\"chain\", \"draw\")).values\n",
        "    \n",
        "    n_jurors = alpha_j.shape[0]\n",
        "    total_samples = alpha_j.shape[1]\n",
        "    \n",
        "    # Randomly select n_draws samples\n",
        "    sample_idx = np.random.choice(total_samples, size=min(n_draws, total_samples), \n",
        "                                 replace=False)\n",
        "    n_draws = len(sample_idx)\n",
        "    \n",
        "    results = {\n",
        "        'majority_acc': np.zeros(n_draws),\n",
        "        'error_corr': np.zeros((n_draws, n_jurors, n_jurors)),\n",
        "        'accuracy_by_size': {k: np.zeros(n_draws) for k in jury_sizes}\n",
        "    }\n",
        "    \n",
        "    rng = np.random.default_rng(42)\n",
        "    \n",
        "    for idx, s in enumerate(sample_idx):\n",
        "        # Sample case difficulty effects for this posterior draw\n",
        "        delta_case = rng.normal(mu_case[s], sigma_case[s], size=n_cases)\n",
        "        \n",
        "        # Generate votes for each case\n",
        "        votes = np.zeros((n_cases, n_jurors), dtype=int)\n",
        "        \n",
        "        for i in range(n_cases):\n",
        "            truth_i = true_states[i]\n",
        "            sign = 1 if truth_i == 1 else -1\n",
        "            \n",
        "            for j in range(n_jurors):\n",
        "                # Combine individual skill + block effect + case difficulty\n",
        "                logit_p = sign * (alpha_j[j, s] + block_effect[block_id[j], s]) + delta_case[i] + trt[j, s]\n",
        "                p = 1 / (1 + np.exp(-logit_p))\n",
        "                votes[i, j] = rng.binomial(1, p)\n",
        "        \n",
        "        # Compute diagnostics\n",
        "        diag = compute_diagnostics(votes, true_states)\n",
        "        results['majority_acc'][idx] = diag['majority_accuracy']\n",
        "        results['error_corr'][idx] = diag['error_corr']\n",
        "        \n",
        "        for k in jury_sizes:\n",
        "            results['accuracy_by_size'][k][idx] = (\n",
        "                majority_accuracy_by_size(votes, true_states, k)\n",
        "            )\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"\\nRunning posterior predictive checks for complete model...\")\n",
        "ppc_full = run_ppc_full_model(idata_full, N_CASES, true_states_blocked, \n",
        "                               BLOCK_ID, n_draws=500)\n",
        "\n",
        "ppc_full_trt = run_ppc_full_model(idata_full_trt, N_CASES, true_states_blocked, \n",
        "                               BLOCK_ID, n_draws=500)\n",
        "\n",
        "# Summarize accuracy by jury size\n",
        "summary_full = summarize_ppc(ppc_full)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MAJORITY ACCURACY BY JURY SIZE (Complete Model)\")\n",
        "print(\"=\"*70)\n",
        "print(summary_full)"
      ],
      "id": "9792b009",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how the increasing size of the voting block does not substantially improve on the accuracy. This pattern is also unfortunately visible in our treatment model. \n"
      ],
      "id": "c49592cb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "summary_full_trt = summarize_ppc(ppc_full_trt)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MAJORITY ACCURACY BY JURY SIZE (Complete Model + Treatment)\")\n",
        "print(\"=\"*70)\n",
        "print(summary_full_trt)\n"
      ],
      "id": "916edf71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The allocation of a heterogenous treatment progromme was not sufficient to break the block voting effects. The increased correlations between voters reduces the number of independent signals in the jury pool. \n"
      ],
      "id": "e876e2c7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot error correlations\n",
        "plot_error_correlation_heatmap(\n",
        "    ppc_full,\n",
        "    title=\"Error Correlation: Complete Model with Block & Case Effects\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ERROR CORRELATION SUMMARY (Complete Model)\")\n",
        "print(\"=\"*70)\n",
        "error_summary = summarize_error_correlation(ppc_full)\n",
        "for key, value in error_summary.items():\n",
        "    print(f\"{key}: {value:.3f}\")"
      ],
      "id": "b7952446",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice the structured patterns in the error correlation heatmap—jurors within the same block (0-4, 5-10, 11-14) show correlated errors. This is the smoking gun: **block effects create dependencies that violate the independence assumption**.\n"
      ],
      "id": "a20bbd7d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot error correlations\n",
        "plot_error_correlation_heatmap(\n",
        "    ppc_full_trt,\n",
        "    title=\"Error Correlation: Complete Model with Block & Case Effects\"\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ERROR CORRELATION SUMMARY (Complete Model)\")\n",
        "print(\"=\"*70)\n",
        "error_summary = summarize_error_correlation(ppc_full_trt)\n",
        "for key, value in error_summary.items():\n",
        "    print(f\"{key}: {value:.3f}\")"
      ],
      "id": "f83c631c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While the correlation patterns change slightly, they remain high and reduce the effectiveness of the majority.\n",
        "\n",
        "Let's visualize how much this matters:"
      ],
      "id": "6b1e09e3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true \n",
        "#| \n",
        "def final_plot(ppc_full):\n",
        "    # Compare accuracy distributions\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot 1: Accuracy by jury size\n",
        "    ax = axes[0]\n",
        "    jury_size_labels = [3, 5, 7, 10, 15]\n",
        "    for i, size in enumerate(jury_size_labels):\n",
        "        accuracies = ppc_full['accuracy_by_size'][size]\n",
        "        ax.violinplot([accuracies], positions=[i], widths=0.7, \n",
        "                    showmeans=True, showmedians=True)\n",
        "\n",
        "    ax.set_xticks(range(len(jury_size_labels)))\n",
        "    ax.set_xticklabels(jury_size_labels)\n",
        "    ax.set_xlabel('Jury Size')\n",
        "    ax.set_ylabel('Majority Accuracy')\n",
        "    ax.set_title('Accuracy Distribution by Jury Size\\n(Complete Model)')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Error correlation distribution\n",
        "    ax = axes[1]\n",
        "    off_diag_corrs = []\n",
        "    for s in range(ppc_full['error_corr'].shape[0]):\n",
        "        mat = ppc_full['error_corr'][s]\n",
        "        n = mat.shape[0]\n",
        "        off_diag_corrs.extend(mat[np.triu_indices(n, k=1)])\n",
        "\n",
        "    ax.hist(off_diag_corrs, bins=50, alpha=0.7, edgecolor='black')\n",
        "    ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Independence')\n",
        "    ax.set_xlabel('Pairwise Error Correlation')\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.set_title('Distribution of Error Correlations\\n(Complete Model)')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Calculate the impact on the Condorcet theorem\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"QUANTIFYING THE VIOLATION\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Mean error correlation: {np.mean(off_diag_corrs):.3f}\")\n",
        "    print(f\"Proportion of positive correlations: {(np.array(off_diag_corrs) > 0).mean():.1%}\")\n",
        "    print(f\"\\nMedian accuracy (15 jurors): {np.median(ppc_full['accuracy_by_size'][15]):.3f}\")\n",
        "    print(f\"Median accuracy (3 jurors): {np.median(ppc_full['accuracy_by_size'][3]):.3f}\")\n",
        "    print(f\"Improvement from larger jury: {np.median(ppc_full['accuracy_by_size'][15]) - np.median(ppc_full['accuracy_by_size'][3]):.3f}\")\n",
        "\n",
        "\n",
        "final_plot(ppc_full)"
      ],
      "id": "e4e87fd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similar final patterns can be seen again with the treatment model.\n"
      ],
      "id": "56742ad3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "final_plot(ppc_full_trt)"
      ],
      "id": "71c6505d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions\n",
        "\n",
        "Through systematic sensitivity analysis, we've identified three critical failure modes for democratic aggregation:\n",
        "\n",
        "1. **Heterogeneous Competence**: Individual differences alone don't break the Condorcet theorem, but they do create inequality in influence. A few highly competent jurors can dominate.\n",
        "\n",
        "2. **Shared Difficulties**: When cases vary in difficulty—especially systematically—jurors make correlated errors. This is the most severe violation: it directly undermines the statistical power of aggregation.\n",
        "\n",
        "3. **Group Effects**: Ideological factions, information silos, and social clustering create structured dependence. Jurors no longer provide independent evidence.\n",
        "\n",
        "The Condorcet Jury Theorem remains a powerful ideal, but its assumptions are fragile. Real-world collective decision-making must account for:\n",
        "- Training and expertise development (reduce heterogeneity)\n",
        "- Procedural safeguards against groupthink (break dependencies)\n",
        "- Recognition of case difficulty (adjust decision rules)\n",
        "- Diverse information sources (counteract block effects)\n",
        "\n",
        "Democracy works—but only when we actively work to satisfy its preconditions."
      ],
      "id": "178d7425"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "applied-bayesian-regression-modeling-env",
      "language": "python",
      "display_name": "applied-bayesian-regression-modeling-env",
      "path": "/Users/nathanielforde/Library/Jupyter/kernels/applied-bayesian-regression-modeling-env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}